12 Jul 2022 14:46:14,186 Executor task launch worker for task 175.0 in stage 10.0 (TID 990) - code for input[0, string, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 64);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     UTF8String value_0 = isNull_0 ?
/* 033 */     null : (i.getUTF8String(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

12 Jul 2022 14:46:14,187 Executor task launch worker for task 175.0 in stage 10.0 (TID 990) - Task 990 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@5ef6ef8d
12 Jul 2022 14:46:14,187 Executor task launch worker for task 175.0 in stage 10.0 (TID 990) - code for input[0, bigint, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     long value_0 = isNull_0 ?
/* 033 */     -1L : (i.getLong(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

12 Jul 2022 14:46:14,187 Executor task launch worker for task 175.0 in stage 10.0 (TID 990) - Task 990 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@5ef6ef8d
12 Jul 2022 14:46:14,187 Executor task launch worker for task 175.0 in stage 10.0 (TID 990) - Writing shuffle index file for mapId 990 with length 1
12 Jul 2022 14:46:14,187 Executor task launch worker for task 175.0 in stage 10.0 (TID 990) - Shuffle index for mapId 990: [0]
12 Jul 2022 14:46:14,188 Executor task launch worker for task 175.0 in stage 10.0 (TID 990) - Finished task 175.0 in stage 10.0 (TID 990). 3956 bytes result sent to driver
12 Jul 2022 14:46:14,188 Executor task launch worker for task 175.0 in stage 10.0 (TID 990) - removing (10, 0) from stageTCMP
12 Jul 2022 14:46:14,188 dispatcher-event-loop-0 - parentName: , name: TaskSet_10.0, runningTasks: 0
12 Jul 2022 14:46:14,188 dispatcher-event-loop-0 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
12 Jul 2022 14:46:14,188 dispatcher-event-loop-0 - Moving to ANY after waiting for 0ms
12 Jul 2022 14:46:14,188 dispatcher-event-loop-0 - Starting task 176.0 in stage 10.0 (TID 991) (MTD-Minhnx12, executor driver, partition 176, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
12 Jul 2022 14:46:14,188 Executor task launch worker for task 176.0 in stage 10.0 (TID 991) - Running task 176.0 in stage 10.0 (TID 991)
12 Jul 2022 14:46:14,188 task-result-getter-2 - Finished task 175.0 in stage 10.0 (TID 990) in 5 ms on MTD-Minhnx12 (executor driver) (185/200)
12 Jul 2022 14:46:14,188 Executor task launch worker for task 176.0 in stage 10.0 (TID 991) - stageTCMP: (10, 0) -> 1
12 Jul 2022 14:46:14,188 dag-scheduler-event-loop - ShuffleMapTask finished on driver
12 Jul 2022 14:46:14,189 Executor task launch worker for task 176.0 in stage 10.0 (TID 991) - Fetching outputs for shuffle 6
12 Jul 2022 14:46:14,189 Executor task launch worker for task 176.0 in stage 10.0 (TID 991) - Convert map statuses for shuffle 6, mappers 0-1, partitions 176-177
12 Jul 2022 14:46:14,190 Executor task launch worker for task 176.0 in stage 10.0 (TID 991) - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
12 Jul 2022 14:46:14,190 Executor task launch worker for task 176.0 in stage 10.0 (TID 991) - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
12 Jul 2022 14:46:14,190 Executor task launch worker for task 176.0 in stage 10.0 (TID 991) - Started 0 remote fetches in 0 ms
12 Jul 2022 14:46:14,190 Executor task launch worker for task 176.0 in stage 10.0 (TID 991) - Start fetching local blocks: 
12 Jul 2022 14:46:14,190 Executor task launch worker for task 176.0 in stage 10.0 (TID 991) - Got local blocks in 0 ms
12 Jul 2022 14:46:14,190 Executor task launch worker for task 176.0 in stage 10.0 (TID 991) - code for 0:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */
/* 030 */
/* 031 */
/* 032 */     mutableStateArray_0[0].write(0, 0L);
/* 033 */     return (mutableStateArray_0[0].getRow());
/* 034 */   }
/* 035 */
/* 036 */
/* 037 */ }

12 Jul 2022 14:46:14,191 Executor task launch worker for task 176.0 in stage 10.0 (TID 991) - code for input[0, string, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 64);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     UTF8String value_0 = isNull_0 ?
/* 033 */     null : (i.getUTF8String(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

12 Jul 2022 14:46:14,191 Executor task launch worker for task 176.0 in stage 10.0 (TID 991) - Task 991 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@48e72885
12 Jul 2022 14:46:14,191 Executor task launch worker for task 176.0 in stage 10.0 (TID 991) - code for input[0, bigint, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     long value_0 = isNull_0 ?
/* 033 */     -1L : (i.getLong(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

12 Jul 2022 14:46:14,191 Executor task launch worker for task 176.0 in stage 10.0 (TID 991) - Task 991 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@48e72885
12 Jul 2022 14:46:14,191 Executor task launch worker for task 176.0 in stage 10.0 (TID 991) - Writing shuffle index file for mapId 991 with length 1
12 Jul 2022 14:46:14,191 Executor task launch worker for task 176.0 in stage 10.0 (TID 991) - Shuffle index for mapId 991: [0]
12 Jul 2022 14:46:14,192 Executor task launch worker for task 176.0 in stage 10.0 (TID 991) - Finished task 176.0 in stage 10.0 (TID 991). 3956 bytes result sent to driver
12 Jul 2022 14:46:14,192 Executor task launch worker for task 176.0 in stage 10.0 (TID 991) - removing (10, 0) from stageTCMP
12 Jul 2022 14:46:14,192 dispatcher-event-loop-0 - parentName: , name: TaskSet_10.0, runningTasks: 0
12 Jul 2022 14:46:14,192 dispatcher-event-loop-0 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
12 Jul 2022 14:46:14,192 dispatcher-event-loop-0 - Moving to ANY after waiting for 0ms
12 Jul 2022 14:46:14,192 dispatcher-event-loop-0 - Starting task 179.0 in stage 10.0 (TID 992) (MTD-Minhnx12, executor driver, partition 179, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
12 Jul 2022 14:46:14,192 Executor task launch worker for task 179.0 in stage 10.0 (TID 992) - Running task 179.0 in stage 10.0 (TID 992)
12 Jul 2022 14:46:14,192 task-result-getter-3 - Finished task 176.0 in stage 10.0 (TID 991) in 4 ms on MTD-Minhnx12 (executor driver) (186/200)
12 Jul 2022 14:46:14,192 Executor task launch worker for task 179.0 in stage 10.0 (TID 992) - stageTCMP: (10, 0) -> 1
12 Jul 2022 14:46:14,193 dag-scheduler-event-loop - ShuffleMapTask finished on driver
12 Jul 2022 14:46:14,194 Executor task launch worker for task 179.0 in stage 10.0 (TID 992) - Fetching outputs for shuffle 6
12 Jul 2022 14:46:14,194 Executor task launch worker for task 179.0 in stage 10.0 (TID 992) - Convert map statuses for shuffle 6, mappers 0-1, partitions 179-180
12 Jul 2022 14:46:14,194 Executor task launch worker for task 179.0 in stage 10.0 (TID 992) - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
12 Jul 2022 14:46:14,194 Executor task launch worker for task 179.0 in stage 10.0 (TID 992) - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
12 Jul 2022 14:46:14,194 Executor task launch worker for task 179.0 in stage 10.0 (TID 992) - Started 0 remote fetches in 0 ms
12 Jul 2022 14:46:14,194 Executor task launch worker for task 179.0 in stage 10.0 (TID 992) - Start fetching local blocks: 
12 Jul 2022 14:46:14,194 Executor task launch worker for task 179.0 in stage 10.0 (TID 992) - Got local blocks in 0 ms
12 Jul 2022 14:46:14,194 Executor task launch worker for task 179.0 in stage 10.0 (TID 992) - code for 0:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */
/* 030 */
/* 031 */
/* 032 */     mutableStateArray_0[0].write(0, 0L);
/* 033 */     return (mutableStateArray_0[0].getRow());
/* 034 */   }
/* 035 */
/* 036 */
/* 037 */ }

12 Jul 2022 14:46:14,195 Executor task launch worker for task 179.0 in stage 10.0 (TID 992) - code for input[0, string, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 64);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     UTF8String value_0 = isNull_0 ?
/* 033 */     null : (i.getUTF8String(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

12 Jul 2022 14:46:14,195 Executor task launch worker for task 179.0 in stage 10.0 (TID 992) - Task 992 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@548f2489
12 Jul 2022 14:46:14,195 Executor task launch worker for task 179.0 in stage 10.0 (TID 992) - code for input[0, bigint, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     long value_0 = isNull_0 ?
/* 033 */     -1L : (i.getLong(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

12 Jul 2022 14:46:14,195 Executor task launch worker for task 179.0 in stage 10.0 (TID 992) - Task 992 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@548f2489
12 Jul 2022 14:46:14,195 Executor task launch worker for task 179.0 in stage 10.0 (TID 992) - Writing shuffle index file for mapId 992 with length 1
12 Jul 2022 14:46:14,196 Executor task launch worker for task 179.0 in stage 10.0 (TID 992) - Shuffle index for mapId 992: [0]
12 Jul 2022 14:46:14,196 Executor task launch worker for task 179.0 in stage 10.0 (TID 992) - Finished task 179.0 in stage 10.0 (TID 992). 3956 bytes result sent to driver
12 Jul 2022 14:46:14,196 Executor task launch worker for task 179.0 in stage 10.0 (TID 992) - removing (10, 0) from stageTCMP
12 Jul 2022 14:46:14,196 dispatcher-event-loop-0 - parentName: , name: TaskSet_10.0, runningTasks: 0
12 Jul 2022 14:46:14,196 dispatcher-event-loop-0 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
12 Jul 2022 14:46:14,196 dispatcher-event-loop-0 - Moving to ANY after waiting for 0ms
12 Jul 2022 14:46:14,196 dispatcher-event-loop-0 - Starting task 180.0 in stage 10.0 (TID 993) (MTD-Minhnx12, executor driver, partition 180, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
12 Jul 2022 14:46:14,196 Executor task launch worker for task 180.0 in stage 10.0 (TID 993) - Running task 180.0 in stage 10.0 (TID 993)
12 Jul 2022 14:46:14,196 task-result-getter-0 - Finished task 179.0 in stage 10.0 (TID 992) in 4 ms on MTD-Minhnx12 (executor driver) (187/200)
12 Jul 2022 14:46:14,197 Executor task launch worker for task 180.0 in stage 10.0 (TID 993) - stageTCMP: (10, 0) -> 1
12 Jul 2022 14:46:14,197 dag-scheduler-event-loop - ShuffleMapTask finished on driver
12 Jul 2022 14:46:14,198 Executor task launch worker for task 180.0 in stage 10.0 (TID 993) - Fetching outputs for shuffle 6
12 Jul 2022 14:46:14,198 Executor task launch worker for task 180.0 in stage 10.0 (TID 993) - Convert map statuses for shuffle 6, mappers 0-1, partitions 180-181
12 Jul 2022 14:46:14,198 Executor task launch worker for task 180.0 in stage 10.0 (TID 993) - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
12 Jul 2022 14:46:14,198 Executor task launch worker for task 180.0 in stage 10.0 (TID 993) - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
12 Jul 2022 14:46:14,198 Executor task launch worker for task 180.0 in stage 10.0 (TID 993) - Started 0 remote fetches in 0 ms
12 Jul 2022 14:46:14,198 Executor task launch worker for task 180.0 in stage 10.0 (TID 993) - Start fetching local blocks: 
12 Jul 2022 14:46:14,198 Executor task launch worker for task 180.0 in stage 10.0 (TID 993) - Got local blocks in 0 ms
12 Jul 2022 14:46:14,198 Executor task launch worker for task 180.0 in stage 10.0 (TID 993) - code for 0:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */
/* 030 */
/* 031 */
/* 032 */     mutableStateArray_0[0].write(0, 0L);
/* 033 */     return (mutableStateArray_0[0].getRow());
/* 034 */   }
/* 035 */
/* 036 */
/* 037 */ }

12 Jul 2022 14:46:14,199 Executor task launch worker for task 180.0 in stage 10.0 (TID 993) - code for input[0, string, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 64);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     UTF8String value_0 = isNull_0 ?
/* 033 */     null : (i.getUTF8String(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

12 Jul 2022 14:46:14,199 Executor task launch worker for task 180.0 in stage 10.0 (TID 993) - Task 993 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@649f2d7b
12 Jul 2022 14:46:14,199 Executor task launch worker for task 180.0 in stage 10.0 (TID 993) - code for input[0, bigint, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     long value_0 = isNull_0 ?
/* 033 */     -1L : (i.getLong(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

12 Jul 2022 14:46:14,200 Executor task launch worker for task 180.0 in stage 10.0 (TID 993) - Task 993 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@649f2d7b
12 Jul 2022 14:46:14,200 Executor task launch worker for task 180.0 in stage 10.0 (TID 993) - Writing shuffle index file for mapId 993 with length 1
12 Jul 2022 14:46:14,200 Executor task launch worker for task 180.0 in stage 10.0 (TID 993) - Shuffle index for mapId 993: [0]
12 Jul 2022 14:46:14,200 Executor task launch worker for task 180.0 in stage 10.0 (TID 993) - Finished task 180.0 in stage 10.0 (TID 993). 3956 bytes result sent to driver
12 Jul 2022 14:46:14,200 Executor task launch worker for task 180.0 in stage 10.0 (TID 993) - removing (10, 0) from stageTCMP
12 Jul 2022 14:46:14,200 dispatcher-event-loop-0 - parentName: , name: TaskSet_10.0, runningTasks: 0
12 Jul 2022 14:46:14,200 dispatcher-event-loop-0 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
12 Jul 2022 14:46:14,200 dispatcher-event-loop-0 - Moving to ANY after waiting for 0ms
12 Jul 2022 14:46:14,200 dispatcher-event-loop-0 - Starting task 184.0 in stage 10.0 (TID 994) (MTD-Minhnx12, executor driver, partition 184, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
12 Jul 2022 14:46:14,201 task-result-getter-1 - Finished task 180.0 in stage 10.0 (TID 993) in 5 ms on MTD-Minhnx12 (executor driver) (188/200)
12 Jul 2022 14:46:14,201 Executor task launch worker for task 184.0 in stage 10.0 (TID 994) - Running task 184.0 in stage 10.0 (TID 994)
12 Jul 2022 14:46:14,201 Executor task launch worker for task 184.0 in stage 10.0 (TID 994) - stageTCMP: (10, 0) -> 1
12 Jul 2022 14:46:14,201 dag-scheduler-event-loop - ShuffleMapTask finished on driver
12 Jul 2022 14:46:14,202 Executor task launch worker for task 184.0 in stage 10.0 (TID 994) - Fetching outputs for shuffle 6
12 Jul 2022 14:46:14,202 Executor task launch worker for task 184.0 in stage 10.0 (TID 994) - Convert map statuses for shuffle 6, mappers 0-1, partitions 184-185
12 Jul 2022 14:46:14,202 Executor task launch worker for task 184.0 in stage 10.0 (TID 994) - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
12 Jul 2022 14:46:14,202 Executor task launch worker for task 184.0 in stage 10.0 (TID 994) - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
12 Jul 2022 14:46:14,202 Executor task launch worker for task 184.0 in stage 10.0 (TID 994) - Started 0 remote fetches in 0 ms
12 Jul 2022 14:46:14,202 Executor task launch worker for task 184.0 in stage 10.0 (TID 994) - Start fetching local blocks: 
12 Jul 2022 14:46:14,202 Executor task launch worker for task 184.0 in stage 10.0 (TID 994) - Got local blocks in 0 ms
12 Jul 2022 14:46:14,203 Executor task launch worker for task 184.0 in stage 10.0 (TID 994) - code for 0:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */
/* 030 */
/* 031 */
/* 032 */     mutableStateArray_0[0].write(0, 0L);
/* 033 */     return (mutableStateArray_0[0].getRow());
/* 034 */   }
/* 035 */
/* 036 */
/* 037 */ }

12 Jul 2022 14:46:14,203 Executor task launch worker for task 184.0 in stage 10.0 (TID 994) - code for input[0, string, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 64);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     UTF8String value_0 = isNull_0 ?
/* 033 */     null : (i.getUTF8String(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

12 Jul 2022 14:46:14,203 Executor task launch worker for task 184.0 in stage 10.0 (TID 994) - Task 994 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@496002a2
12 Jul 2022 14:46:14,204 Executor task launch worker for task 184.0 in stage 10.0 (TID 994) - code for input[0, bigint, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     long value_0 = isNull_0 ?
/* 033 */     -1L : (i.getLong(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

12 Jul 2022 14:46:14,204 Executor task launch worker for task 184.0 in stage 10.0 (TID 994) - Task 994 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@496002a2
12 Jul 2022 14:46:14,204 Executor task launch worker for task 184.0 in stage 10.0 (TID 994) - Writing shuffle index file for mapId 994 with length 1
12 Jul 2022 14:46:14,204 Executor task launch worker for task 184.0 in stage 10.0 (TID 994) - Shuffle index for mapId 994: [0]
12 Jul 2022 14:46:14,204 Executor task launch worker for task 184.0 in stage 10.0 (TID 994) - Finished task 184.0 in stage 10.0 (TID 994). 3956 bytes result sent to driver
12 Jul 2022 14:46:14,204 Executor task launch worker for task 184.0 in stage 10.0 (TID 994) - removing (10, 0) from stageTCMP
12 Jul 2022 14:46:14,205 dispatcher-event-loop-0 - parentName: , name: TaskSet_10.0, runningTasks: 0
12 Jul 2022 14:46:14,205 dispatcher-event-loop-0 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
12 Jul 2022 14:46:14,205 dispatcher-event-loop-0 - Moving to ANY after waiting for 0ms
12 Jul 2022 14:46:14,205 dispatcher-event-loop-0 - Starting task 185.0 in stage 10.0 (TID 995) (MTD-Minhnx12, executor driver, partition 185, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
12 Jul 2022 14:46:14,205 task-result-getter-2 - Finished task 184.0 in stage 10.0 (TID 994) in 5 ms on MTD-Minhnx12 (executor driver) (189/200)
12 Jul 2022 14:46:14,205 Executor task launch worker for task 185.0 in stage 10.0 (TID 995) - Running task 185.0 in stage 10.0 (TID 995)
12 Jul 2022 14:46:14,205 Executor task launch worker for task 185.0 in stage 10.0 (TID 995) - stageTCMP: (10, 0) -> 1
12 Jul 2022 14:46:14,205 dag-scheduler-event-loop - ShuffleMapTask finished on driver
12 Jul 2022 14:46:14,207 Executor task launch worker for task 185.0 in stage 10.0 (TID 995) - Fetching outputs for shuffle 6
12 Jul 2022 14:46:14,207 Executor task launch worker for task 185.0 in stage 10.0 (TID 995) - Convert map statuses for shuffle 6, mappers 0-1, partitions 185-186
12 Jul 2022 14:46:14,207 Executor task launch worker for task 185.0 in stage 10.0 (TID 995) - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
12 Jul 2022 14:46:14,207 Executor task launch worker for task 185.0 in stage 10.0 (TID 995) - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
12 Jul 2022 14:46:14,207 Executor task launch worker for task 185.0 in stage 10.0 (TID 995) - Started 0 remote fetches in 0 ms
12 Jul 2022 14:46:14,207 Executor task launch worker for task 185.0 in stage 10.0 (TID 995) - Start fetching local blocks: 
12 Jul 2022 14:46:14,207 Executor task launch worker for task 185.0 in stage 10.0 (TID 995) - Got local blocks in 0 ms
12 Jul 2022 14:46:14,207 Executor task launch worker for task 185.0 in stage 10.0 (TID 995) - code for 0:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */
/* 030 */
/* 031 */
/* 032 */     mutableStateArray_0[0].write(0, 0L);
/* 033 */     return (mutableStateArray_0[0].getRow());
/* 034 */   }
/* 035 */
/* 036 */
/* 037 */ }

12 Jul 2022 14:46:14,208 Executor task launch worker for task 185.0 in stage 10.0 (TID 995) - code for input[0, string, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 64);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     UTF8String value_0 = isNull_0 ?
/* 033 */     null : (i.getUTF8String(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

12 Jul 2022 14:46:14,208 Executor task launch worker for task 185.0 in stage 10.0 (TID 995) - Task 995 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@3d9e3e17
12 Jul 2022 14:46:14,208 Executor task launch worker for task 185.0 in stage 10.0 (TID 995) - code for input[0, bigint, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     long value_0 = isNull_0 ?
/* 033 */     -1L : (i.getLong(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

12 Jul 2022 14:46:14,208 Executor task launch worker for task 185.0 in stage 10.0 (TID 995) - Task 995 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@3d9e3e17
12 Jul 2022 14:46:14,208 Executor task launch worker for task 185.0 in stage 10.0 (TID 995) - Writing shuffle index file for mapId 995 with length 1
12 Jul 2022 14:46:14,209 Executor task launch worker for task 185.0 in stage 10.0 (TID 995) - Shuffle index for mapId 995: [0]
12 Jul 2022 14:46:14,209 Executor task launch worker for task 185.0 in stage 10.0 (TID 995) - Finished task 185.0 in stage 10.0 (TID 995). 3956 bytes result sent to driver
12 Jul 2022 14:46:14,209 Executor task launch worker for task 185.0 in stage 10.0 (TID 995) - removing (10, 0) from stageTCMP
12 Jul 2022 14:46:14,209 dispatcher-event-loop-0 - parentName: , name: TaskSet_10.0, runningTasks: 0
12 Jul 2022 14:46:14,209 dispatcher-event-loop-0 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
12 Jul 2022 14:46:14,209 dispatcher-event-loop-0 - Moving to ANY after waiting for 0ms
12 Jul 2022 14:46:14,209 dispatcher-event-loop-0 - Starting task 186.0 in stage 10.0 (TID 996) (MTD-Minhnx12, executor driver, partition 186, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
12 Jul 2022 14:46:14,209 task-result-getter-3 - Finished task 185.0 in stage 10.0 (TID 995) in 4 ms on MTD-Minhnx12 (executor driver) (190/200)
12 Jul 2022 14:46:14,209 Executor task launch worker for task 186.0 in stage 10.0 (TID 996) - Running task 186.0 in stage 10.0 (TID 996)
12 Jul 2022 14:46:14,210 Executor task launch worker for task 186.0 in stage 10.0 (TID 996) - stageTCMP: (10, 0) -> 1
12 Jul 2022 14:46:14,210 dag-scheduler-event-loop - ShuffleMapTask finished on driver
12 Jul 2022 14:46:14,211 Executor task launch worker for task 186.0 in stage 10.0 (TID 996) - Fetching outputs for shuffle 6
12 Jul 2022 14:46:14,211 Executor task launch worker for task 186.0 in stage 10.0 (TID 996) - Convert map statuses for shuffle 6, mappers 0-1, partitions 186-187
12 Jul 2022 14:46:14,211 Executor task launch worker for task 186.0 in stage 10.0 (TID 996) - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
12 Jul 2022 14:46:14,211 Executor task launch worker for task 186.0 in stage 10.0 (TID 996) - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
12 Jul 2022 14:46:14,211 Executor task launch worker for task 186.0 in stage 10.0 (TID 996) - Started 0 remote fetches in 0 ms
12 Jul 2022 14:46:14,211 Executor task launch worker for task 186.0 in stage 10.0 (TID 996) - Start fetching local blocks: 
12 Jul 2022 14:46:14,211 Executor task launch worker for task 186.0 in stage 10.0 (TID 996) - Got local blocks in 0 ms
12 Jul 2022 14:46:14,212 Executor task launch worker for task 186.0 in stage 10.0 (TID 996) - code for 0:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */
/* 030 */
/* 031 */
/* 032 */     mutableStateArray_0[0].write(0, 0L);
/* 033 */     return (mutableStateArray_0[0].getRow());
/* 034 */   }
/* 035 */
/* 036 */
/* 037 */ }

12 Jul 2022 14:46:14,212 Executor task launch worker for task 186.0 in stage 10.0 (TID 996) - code for input[0, string, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 64);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     UTF8String value_0 = isNull_0 ?
/* 033 */     null : (i.getUTF8String(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

12 Jul 2022 14:46:14,213 Executor task launch worker for task 186.0 in stage 10.0 (TID 996) - Task 996 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@334b7a0d
12 Jul 2022 14:46:14,213 Executor task launch worker for task 186.0 in stage 10.0 (TID 996) - code for input[0, bigint, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     long value_0 = isNull_0 ?
/* 033 */     -1L : (i.getLong(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

12 Jul 2022 14:46:14,213 Executor task launch worker for task 186.0 in stage 10.0 (TID 996) - Task 996 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@334b7a0d
12 Jul 2022 14:46:14,213 Executor task launch worker for task 186.0 in stage 10.0 (TID 996) - Writing shuffle index file for mapId 996 with length 1
12 Jul 2022 14:46:14,213 Executor task launch worker for task 186.0 in stage 10.0 (TID 996) - Shuffle index for mapId 996: [0]
12 Jul 2022 14:46:14,214 Executor task launch worker for task 186.0 in stage 10.0 (TID 996) - Finished task 186.0 in stage 10.0 (TID 996). 3956 bytes result sent to driver
12 Jul 2022 14:46:14,214 Executor task launch worker for task 186.0 in stage 10.0 (TID 996) - removing (10, 0) from stageTCMP
12 Jul 2022 14:46:14,214 dispatcher-event-loop-0 - parentName: , name: TaskSet_10.0, runningTasks: 0
12 Jul 2022 14:46:14,214 dispatcher-event-loop-0 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
12 Jul 2022 14:46:14,214 dispatcher-event-loop-0 - Moving to ANY after waiting for 0ms
12 Jul 2022 14:46:14,214 dispatcher-event-loop-0 - Starting task 187.0 in stage 10.0 (TID 997) (MTD-Minhnx12, executor driver, partition 187, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
12 Jul 2022 14:46:14,214 Executor task launch worker for task 187.0 in stage 10.0 (TID 997) - Running task 187.0 in stage 10.0 (TID 997)
12 Jul 2022 14:46:14,214 task-result-getter-0 - Finished task 186.0 in stage 10.0 (TID 996) in 5 ms on MTD-Minhnx12 (executor driver) (191/200)
12 Jul 2022 14:46:14,214 Executor task launch worker for task 187.0 in stage 10.0 (TID 997) - stageTCMP: (10, 0) -> 1
12 Jul 2022 14:46:14,215 dag-scheduler-event-loop - ShuffleMapTask finished on driver
12 Jul 2022 14:46:14,216 Executor task launch worker for task 187.0 in stage 10.0 (TID 997) - Fetching outputs for shuffle 6
12 Jul 2022 14:46:14,216 Executor task launch worker for task 187.0 in stage 10.0 (TID 997) - Convert map statuses for shuffle 6, mappers 0-1, partitions 187-188
12 Jul 2022 14:46:14,216 Executor task launch worker for task 187.0 in stage 10.0 (TID 997) - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
12 Jul 2022 14:46:14,216 Executor task launch worker for task 187.0 in stage 10.0 (TID 997) - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
12 Jul 2022 14:46:14,216 Executor task launch worker for task 187.0 in stage 10.0 (TID 997) - Started 0 remote fetches in 0 ms
12 Jul 2022 14:46:14,216 Executor task launch worker for task 187.0 in stage 10.0 (TID 997) - Start fetching local blocks: 
12 Jul 2022 14:46:14,216 Executor task launch worker for task 187.0 in stage 10.0 (TID 997) - Got local blocks in 0 ms
12 Jul 2022 14:46:14,217 Executor task launch worker for task 187.0 in stage 10.0 (TID 997) - code for 0:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */
/* 030 */
/* 031 */
/* 032 */     mutableStateArray_0[0].write(0, 0L);
/* 033 */     return (mutableStateArray_0[0].getRow());
/* 034 */   }
/* 035 */
/* 036 */
/* 037 */ }

12 Jul 2022 14:46:14,217 Executor task launch worker for task 187.0 in stage 10.0 (TID 997) - code for input[0, string, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 64);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     UTF8String value_0 = isNull_0 ?
/* 033 */     null : (i.getUTF8String(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

12 Jul 2022 14:46:14,217 Executor task launch worker for task 187.0 in stage 10.0 (TID 997) - Task 997 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@727c37fe
12 Jul 2022 14:46:14,218 Executor task launch worker for task 187.0 in stage 10.0 (TID 997) - code for input[0, bigint, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     long value_0 = isNull_0 ?
/* 033 */     -1L : (i.getLong(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

12 Jul 2022 14:46:14,218 Executor task launch worker for task 187.0 in stage 10.0 (TID 997) - Task 997 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@727c37fe
12 Jul 2022 14:46:14,218 Executor task launch worker for task 187.0 in stage 10.0 (TID 997) - Writing shuffle index file for mapId 997 with length 1
12 Jul 2022 14:46:14,218 Executor task launch worker for task 187.0 in stage 10.0 (TID 997) - Shuffle index for mapId 997: [0]
12 Jul 2022 14:46:14,218 Executor task launch worker for task 187.0 in stage 10.0 (TID 997) - Finished task 187.0 in stage 10.0 (TID 997). 3956 bytes result sent to driver
12 Jul 2022 14:46:14,218 Executor task launch worker for task 187.0 in stage 10.0 (TID 997) - removing (10, 0) from stageTCMP
12 Jul 2022 14:46:14,218 dispatcher-event-loop-0 - parentName: , name: TaskSet_10.0, runningTasks: 0
12 Jul 2022 14:46:14,218 dispatcher-event-loop-0 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
12 Jul 2022 14:46:14,218 dispatcher-event-loop-0 - Moving to ANY after waiting for 0ms
12 Jul 2022 14:46:14,219 dispatcher-event-loop-0 - Starting task 188.0 in stage 10.0 (TID 998) (MTD-Minhnx12, executor driver, partition 188, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
12 Jul 2022 14:46:14,219 Executor task launch worker for task 188.0 in stage 10.0 (TID 998) - Running task 188.0 in stage 10.0 (TID 998)
12 Jul 2022 14:46:14,219 task-result-getter-1 - Finished task 187.0 in stage 10.0 (TID 997) in 5 ms on MTD-Minhnx12 (executor driver) (192/200)
12 Jul 2022 14:46:14,219 Executor task launch worker for task 188.0 in stage 10.0 (TID 998) - stageTCMP: (10, 0) -> 1
12 Jul 2022 14:46:14,219 dag-scheduler-event-loop - ShuffleMapTask finished on driver
12 Jul 2022 14:46:14,221 Executor task launch worker for task 188.0 in stage 10.0 (TID 998) - Fetching outputs for shuffle 6
12 Jul 2022 14:46:14,221 Executor task launch worker for task 188.0 in stage 10.0 (TID 998) - Convert map statuses for shuffle 6, mappers 0-1, partitions 188-189
12 Jul 2022 14:46:14,221 Executor task launch worker for task 188.0 in stage 10.0 (TID 998) - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
12 Jul 2022 14:46:14,221 Executor task launch worker for task 188.0 in stage 10.0 (TID 998) - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
12 Jul 2022 14:46:14,221 Executor task launch worker for task 188.0 in stage 10.0 (TID 998) - Started 0 remote fetches in 0 ms
12 Jul 2022 14:46:14,221 Executor task launch worker for task 188.0 in stage 10.0 (TID 998) - Start fetching local blocks: 
12 Jul 2022 14:46:14,221 Executor task launch worker for task 188.0 in stage 10.0 (TID 998) - Got local blocks in 0 ms
12 Jul 2022 14:46:14,222 Executor task launch worker for task 188.0 in stage 10.0 (TID 998) - code for 0:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */
/* 030 */
/* 031 */
/* 032 */     mutableStateArray_0[0].write(0, 0L);
/* 033 */     return (mutableStateArray_0[0].getRow());
/* 034 */   }
/* 035 */
/* 036 */
/* 037 */ }

12 Jul 2022 14:46:14,223 Executor task launch worker for task 188.0 in stage 10.0 (TID 998) - code for input[0, string, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 64);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     UTF8String value_0 = isNull_0 ?
/* 033 */     null : (i.getUTF8String(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

12 Jul 2022 14:46:14,223 Executor task launch worker for task 188.0 in stage 10.0 (TID 998) - Task 998 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@2d3fac35
12 Jul 2022 14:46:14,223 Executor task launch worker for task 188.0 in stage 10.0 (TID 998) - code for input[0, bigint, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     long value_0 = isNull_0 ?
/* 033 */     -1L : (i.getLong(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

12 Jul 2022 14:46:14,223 Executor task launch worker for task 188.0 in stage 10.0 (TID 998) - Task 998 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@2d3fac35
12 Jul 2022 14:46:14,223 Executor task launch worker for task 188.0 in stage 10.0 (TID 998) - Writing shuffle index file for mapId 998 with length 1
12 Jul 2022 14:46:14,223 Executor task launch worker for task 188.0 in stage 10.0 (TID 998) - Shuffle index for mapId 998: [0]
12 Jul 2022 14:46:14,224 Executor task launch worker for task 188.0 in stage 10.0 (TID 998) - Finished task 188.0 in stage 10.0 (TID 998). 3956 bytes result sent to driver
12 Jul 2022 14:46:14,224 Executor task launch worker for task 188.0 in stage 10.0 (TID 998) - removing (10, 0) from stageTCMP
12 Jul 2022 14:46:14,224 dispatcher-event-loop-0 - parentName: , name: TaskSet_10.0, runningTasks: 0
12 Jul 2022 14:46:14,224 dispatcher-event-loop-0 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
12 Jul 2022 14:46:14,224 dispatcher-event-loop-0 - Moving to ANY after waiting for 0ms
12 Jul 2022 14:46:14,224 dispatcher-event-loop-0 - Starting task 191.0 in stage 10.0 (TID 999) (MTD-Minhnx12, executor driver, partition 191, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
12 Jul 2022 14:46:14,224 Executor task launch worker for task 191.0 in stage 10.0 (TID 999) - Running task 191.0 in stage 10.0 (TID 999)
12 Jul 2022 14:46:14,224 task-result-getter-2 - Finished task 188.0 in stage 10.0 (TID 998) in 6 ms on MTD-Minhnx12 (executor driver) (193/200)
12 Jul 2022 14:46:14,224 Executor task launch worker for task 191.0 in stage 10.0 (TID 999) - stageTCMP: (10, 0) -> 1
12 Jul 2022 14:46:14,225 dag-scheduler-event-loop - ShuffleMapTask finished on driver
12 Jul 2022 14:46:14,226 Executor task launch worker for task 191.0 in stage 10.0 (TID 999) - Fetching outputs for shuffle 6
12 Jul 2022 14:46:14,226 Executor task launch worker for task 191.0 in stage 10.0 (TID 999) - Convert map statuses for shuffle 6, mappers 0-1, partitions 191-192
12 Jul 2022 14:46:14,226 Executor task launch worker for task 191.0 in stage 10.0 (TID 999) - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
12 Jul 2022 14:46:14,226 Executor task launch worker for task 191.0 in stage 10.0 (TID 999) - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
12 Jul 2022 14:46:14,226 Executor task launch worker for task 191.0 in stage 10.0 (TID 999) - Started 0 remote fetches in 0 ms
12 Jul 2022 14:46:14,226 Executor task launch worker for task 191.0 in stage 10.0 (TID 999) - Start fetching local blocks: 
12 Jul 2022 14:46:14,226 Executor task launch worker for task 191.0 in stage 10.0 (TID 999) - Got local blocks in 0 ms
12 Jul 2022 14:46:14,226 Executor task launch worker for task 191.0 in stage 10.0 (TID 999) - code for 0:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */
/* 030 */
/* 031 */
/* 032 */     mutableStateArray_0[0].write(0, 0L);
/* 033 */     return (mutableStateArray_0[0].getRow());
/* 034 */   }
/* 035 */
/* 036 */
/* 037 */ }

12 Jul 2022 14:46:14,227 Executor task launch worker for task 191.0 in stage 10.0 (TID 999) - code for input[0, string, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 64);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     UTF8String value_0 = isNull_0 ?
/* 033 */     null : (i.getUTF8String(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

12 Jul 2022 14:46:14,227 Executor task launch worker for task 191.0 in stage 10.0 (TID 999) - Task 999 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@4800bbe2
12 Jul 2022 14:46:14,227 Executor task launch worker for task 191.0 in stage 10.0 (TID 999) - code for input[0, bigint, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     long value_0 = isNull_0 ?
/* 033 */     -1L : (i.getLong(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

12 Jul 2022 14:46:14,228 Executor task launch worker for task 191.0 in stage 10.0 (TID 999) - Task 999 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@4800bbe2
12 Jul 2022 14:46:14,228 Executor task launch worker for task 191.0 in stage 10.0 (TID 999) - Writing shuffle index file for mapId 999 with length 1
12 Jul 2022 14:46:14,228 Executor task launch worker for task 191.0 in stage 10.0 (TID 999) - Shuffle index for mapId 999: [0]
12 Jul 2022 14:46:14,228 Executor task launch worker for task 191.0 in stage 10.0 (TID 999) - Finished task 191.0 in stage 10.0 (TID 999). 3956 bytes result sent to driver
12 Jul 2022 14:46:14,228 Executor task launch worker for task 191.0 in stage 10.0 (TID 999) - removing (10, 0) from stageTCMP
12 Jul 2022 14:46:14,228 dispatcher-event-loop-0 - parentName: , name: TaskSet_10.0, runningTasks: 0
12 Jul 2022 14:46:14,228 dispatcher-event-loop-0 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
12 Jul 2022 14:46:14,228 dispatcher-event-loop-0 - Moving to ANY after waiting for 0ms
12 Jul 2022 14:46:14,228 dispatcher-event-loop-0 - Starting task 192.0 in stage 10.0 (TID 1000) (MTD-Minhnx12, executor driver, partition 192, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
12 Jul 2022 14:46:14,229 Executor task launch worker for task 192.0 in stage 10.0 (TID 1000) - Running task 192.0 in stage 10.0 (TID 1000)
12 Jul 2022 14:46:14,229 task-result-getter-3 - Finished task 191.0 in stage 10.0 (TID 999) in 5 ms on MTD-Minhnx12 (executor driver) (194/200)
12 Jul 2022 14:46:14,229 Executor task launch worker for task 192.0 in stage 10.0 (TID 1000) - stageTCMP: (10, 0) -> 1
12 Jul 2022 14:46:14,229 dag-scheduler-event-loop - ShuffleMapTask finished on driver
12 Jul 2022 14:46:14,230 Executor task launch worker for task 192.0 in stage 10.0 (TID 1000) - Fetching outputs for shuffle 6
12 Jul 2022 14:46:14,230 Executor task launch worker for task 192.0 in stage 10.0 (TID 1000) - Convert map statuses for shuffle 6, mappers 0-1, partitions 192-193
12 Jul 2022 14:46:14,230 Executor task launch worker for task 192.0 in stage 10.0 (TID 1000) - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
12 Jul 2022 14:46:14,230 Executor task launch worker for task 192.0 in stage 10.0 (TID 1000) - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
12 Jul 2022 14:46:14,230 Executor task launch worker for task 192.0 in stage 10.0 (TID 1000) - Started 0 remote fetches in 0 ms
12 Jul 2022 14:46:14,230 Executor task launch worker for task 192.0 in stage 10.0 (TID 1000) - Start fetching local blocks: 
12 Jul 2022 14:46:14,230 Executor task launch worker for task 192.0 in stage 10.0 (TID 1000) - Got local blocks in 0 ms
12 Jul 2022 14:46:14,231 Executor task launch worker for task 192.0 in stage 10.0 (TID 1000) - code for 0:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */
/* 030 */
/* 031 */
/* 032 */     mutableStateArray_0[0].write(0, 0L);
/* 033 */     return (mutableStateArray_0[0].getRow());
/* 034 */   }
/* 035 */
/* 036 */
/* 037 */ }

12 Jul 2022 14:46:14,232 Executor task launch worker for task 192.0 in stage 10.0 (TID 1000) - code for input[0, string, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 64);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     UTF8String value_0 = isNull_0 ?
/* 033 */     null : (i.getUTF8String(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

12 Jul 2022 14:46:14,232 Executor task launch worker for task 192.0 in stage 10.0 (TID 1000) - Task 1000 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@7eae1b90
12 Jul 2022 14:46:14,232 Executor task launch worker for task 192.0 in stage 10.0 (TID 1000) - code for input[0, bigint, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     long value_0 = isNull_0 ?
/* 033 */     -1L : (i.getLong(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

12 Jul 2022 14:46:14,233 Executor task launch worker for task 192.0 in stage 10.0 (TID 1000) - Task 1000 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@7eae1b90
12 Jul 2022 14:46:14,233 Executor task launch worker for task 192.0 in stage 10.0 (TID 1000) - Writing shuffle index file for mapId 1000 with length 1
12 Jul 2022 14:46:14,233 Executor task launch worker for task 192.0 in stage 10.0 (TID 1000) - Shuffle index for mapId 1000: [0]
12 Jul 2022 14:46:14,233 Executor task launch worker for task 192.0 in stage 10.0 (TID 1000) - Finished task 192.0 in stage 10.0 (TID 1000). 3956 bytes result sent to driver
12 Jul 2022 14:46:14,233 Executor task launch worker for task 192.0 in stage 10.0 (TID 1000) - removing (10, 0) from stageTCMP
12 Jul 2022 14:46:14,233 dispatcher-event-loop-0 - parentName: , name: TaskSet_10.0, runningTasks: 0
12 Jul 2022 14:46:14,234 dispatcher-event-loop-0 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
12 Jul 2022 14:46:14,234 dispatcher-event-loop-0 - Moving to ANY after waiting for 0ms
12 Jul 2022 14:46:14,234 dispatcher-event-loop-0 - Starting task 195.0 in stage 10.0 (TID 1001) (MTD-Minhnx12, executor driver, partition 195, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
12 Jul 2022 14:46:14,234 Executor task launch worker for task 195.0 in stage 10.0 (TID 1001) - Running task 195.0 in stage 10.0 (TID 1001)
12 Jul 2022 14:46:14,234 task-result-getter-0 - Finished task 192.0 in stage 10.0 (TID 1000) in 6 ms on MTD-Minhnx12 (executor driver) (195/200)
12 Jul 2022 14:46:14,234 Executor task launch worker for task 195.0 in stage 10.0 (TID 1001) - stageTCMP: (10, 0) -> 1
12 Jul 2022 14:46:14,234 dag-scheduler-event-loop - ShuffleMapTask finished on driver
12 Jul 2022 14:46:14,236 Executor task launch worker for task 195.0 in stage 10.0 (TID 1001) - Fetching outputs for shuffle 6
12 Jul 2022 14:46:14,236 Executor task launch worker for task 195.0 in stage 10.0 (TID 1001) - Convert map statuses for shuffle 6, mappers 0-1, partitions 195-196
12 Jul 2022 14:46:14,236 Executor task launch worker for task 195.0 in stage 10.0 (TID 1001) - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
12 Jul 2022 14:46:14,236 Executor task launch worker for task 195.0 in stage 10.0 (TID 1001) - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
12 Jul 2022 14:46:14,236 Executor task launch worker for task 195.0 in stage 10.0 (TID 1001) - Started 0 remote fetches in 0 ms
12 Jul 2022 14:46:14,236 Executor task launch worker for task 195.0 in stage 10.0 (TID 1001) - Start fetching local blocks: 
12 Jul 2022 14:46:14,236 Executor task launch worker for task 195.0 in stage 10.0 (TID 1001) - Got local blocks in 0 ms
12 Jul 2022 14:46:14,237 Executor task launch worker for task 195.0 in stage 10.0 (TID 1001) - code for 0:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */
/* 030 */
/* 031 */
/* 032 */     mutableStateArray_0[0].write(0, 0L);
/* 033 */     return (mutableStateArray_0[0].getRow());
/* 034 */   }
/* 035 */
/* 036 */
/* 037 */ }

12 Jul 2022 14:46:14,238 Executor task launch worker for task 195.0 in stage 10.0 (TID 1001) - code for input[0, string, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 64);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     UTF8String value_0 = isNull_0 ?
/* 033 */     null : (i.getUTF8String(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

12 Jul 2022 14:46:14,238 Executor task launch worker for task 195.0 in stage 10.0 (TID 1001) - Task 1001 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@5c3d0588
12 Jul 2022 14:46:14,238 Executor task launch worker for task 195.0 in stage 10.0 (TID 1001) - code for input[0, bigint, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     long value_0 = isNull_0 ?
/* 033 */     -1L : (i.getLong(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

12 Jul 2022 14:46:14,238 Executor task launch worker for task 195.0 in stage 10.0 (TID 1001) - Task 1001 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@5c3d0588
12 Jul 2022 14:46:14,238 Executor task launch worker for task 195.0 in stage 10.0 (TID 1001) - Writing shuffle index file for mapId 1001 with length 1
12 Jul 2022 14:46:14,239 Executor task launch worker for task 195.0 in stage 10.0 (TID 1001) - Shuffle index for mapId 1001: [0]
12 Jul 2022 14:46:14,239 Executor task launch worker for task 195.0 in stage 10.0 (TID 1001) - Finished task 195.0 in stage 10.0 (TID 1001). 3956 bytes result sent to driver
12 Jul 2022 14:46:14,239 Executor task launch worker for task 195.0 in stage 10.0 (TID 1001) - removing (10, 0) from stageTCMP
12 Jul 2022 14:46:14,239 dispatcher-event-loop-0 - parentName: , name: TaskSet_10.0, runningTasks: 0
12 Jul 2022 14:46:14,239 dispatcher-event-loop-0 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
12 Jul 2022 14:46:14,239 dispatcher-event-loop-0 - Moving to ANY after waiting for 0ms
12 Jul 2022 14:46:14,239 dispatcher-event-loop-0 - Starting task 196.0 in stage 10.0 (TID 1002) (MTD-Minhnx12, executor driver, partition 196, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
12 Jul 2022 14:46:14,240 Executor task launch worker for task 196.0 in stage 10.0 (TID 1002) - Running task 196.0 in stage 10.0 (TID 1002)
12 Jul 2022 14:46:14,240 task-result-getter-1 - Finished task 195.0 in stage 10.0 (TID 1001) in 6 ms on MTD-Minhnx12 (executor driver) (196/200)
12 Jul 2022 14:46:14,240 Executor task launch worker for task 196.0 in stage 10.0 (TID 1002) - stageTCMP: (10, 0) -> 1
12 Jul 2022 14:46:14,240 dag-scheduler-event-loop - ShuffleMapTask finished on driver
12 Jul 2022 14:46:14,242 Executor task launch worker for task 196.0 in stage 10.0 (TID 1002) - Fetching outputs for shuffle 6
12 Jul 2022 14:46:14,242 Executor task launch worker for task 196.0 in stage 10.0 (TID 1002) - Convert map statuses for shuffle 6, mappers 0-1, partitions 196-197
12 Jul 2022 14:46:14,242 Executor task launch worker for task 196.0 in stage 10.0 (TID 1002) - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
12 Jul 2022 14:46:14,242 Executor task launch worker for task 196.0 in stage 10.0 (TID 1002) - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
12 Jul 2022 14:46:14,242 Executor task launch worker for task 196.0 in stage 10.0 (TID 1002) - Started 0 remote fetches in 0 ms
12 Jul 2022 14:46:14,242 Executor task launch worker for task 196.0 in stage 10.0 (TID 1002) - Start fetching local blocks: 
12 Jul 2022 14:46:14,242 Executor task launch worker for task 196.0 in stage 10.0 (TID 1002) - Got local blocks in 0 ms
12 Jul 2022 14:46:14,243 Executor task launch worker for task 196.0 in stage 10.0 (TID 1002) - code for 0:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */
/* 030 */
/* 031 */
/* 032 */     mutableStateArray_0[0].write(0, 0L);
/* 033 */     return (mutableStateArray_0[0].getRow());
/* 034 */   }
/* 035 */
/* 036 */
/* 037 */ }

12 Jul 2022 14:46:14,244 Executor task launch worker for task 196.0 in stage 10.0 (TID 1002) - code for input[0, string, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 64);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     UTF8String value_0 = isNull_0 ?
/* 033 */     null : (i.getUTF8String(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

12 Jul 2022 14:46:14,244 Executor task launch worker for task 196.0 in stage 10.0 (TID 1002) - Task 1002 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@27cdd89a
12 Jul 2022 14:46:14,244 Executor task launch worker for task 196.0 in stage 10.0 (TID 1002) - code for input[0, bigint, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     long value_0 = isNull_0 ?
/* 033 */     -1L : (i.getLong(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

12 Jul 2022 14:46:14,245 Executor task launch worker for task 196.0 in stage 10.0 (TID 1002) - Task 1002 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@27cdd89a
12 Jul 2022 14:46:14,245 Executor task launch worker for task 196.0 in stage 10.0 (TID 1002) - Writing shuffle index file for mapId 1002 with length 1
12 Jul 2022 14:46:14,245 Executor task launch worker for task 196.0 in stage 10.0 (TID 1002) - Shuffle index for mapId 1002: [0]
12 Jul 2022 14:46:14,245 Executor task launch worker for task 196.0 in stage 10.0 (TID 1002) - Finished task 196.0 in stage 10.0 (TID 1002). 3956 bytes result sent to driver
12 Jul 2022 14:46:14,245 Executor task launch worker for task 196.0 in stage 10.0 (TID 1002) - removing (10, 0) from stageTCMP
12 Jul 2022 14:46:14,245 dispatcher-event-loop-0 - parentName: , name: TaskSet_10.0, runningTasks: 0
12 Jul 2022 14:46:14,245 dispatcher-event-loop-0 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
12 Jul 2022 14:46:14,245 dispatcher-event-loop-0 - Moving to ANY after waiting for 0ms
12 Jul 2022 14:46:14,245 dispatcher-event-loop-0 - Starting task 197.0 in stage 10.0 (TID 1003) (MTD-Minhnx12, executor driver, partition 197, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
12 Jul 2022 14:46:14,246 Executor task launch worker for task 197.0 in stage 10.0 (TID 1003) - Running task 197.0 in stage 10.0 (TID 1003)
12 Jul 2022 14:46:14,246 task-result-getter-2 - Finished task 196.0 in stage 10.0 (TID 1002) in 7 ms on MTD-Minhnx12 (executor driver) (197/200)
12 Jul 2022 14:46:14,246 Executor task launch worker for task 197.0 in stage 10.0 (TID 1003) - stageTCMP: (10, 0) -> 1
12 Jul 2022 14:46:14,246 dag-scheduler-event-loop - ShuffleMapTask finished on driver
12 Jul 2022 14:46:14,247 Executor task launch worker for task 197.0 in stage 10.0 (TID 1003) - Fetching outputs for shuffle 6
12 Jul 2022 14:46:14,247 Executor task launch worker for task 197.0 in stage 10.0 (TID 1003) - Convert map statuses for shuffle 6, mappers 0-1, partitions 197-198
12 Jul 2022 14:46:14,247 Executor task launch worker for task 197.0 in stage 10.0 (TID 1003) - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
12 Jul 2022 14:46:14,247 Executor task launch worker for task 197.0 in stage 10.0 (TID 1003) - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
12 Jul 2022 14:46:14,247 Executor task launch worker for task 197.0 in stage 10.0 (TID 1003) - Started 0 remote fetches in 0 ms
12 Jul 2022 14:46:14,247 Executor task launch worker for task 197.0 in stage 10.0 (TID 1003) - Start fetching local blocks: 
12 Jul 2022 14:46:14,247 Executor task launch worker for task 197.0 in stage 10.0 (TID 1003) - Got local blocks in 0 ms
12 Jul 2022 14:46:14,248 Executor task launch worker for task 197.0 in stage 10.0 (TID 1003) - code for 0:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */
/* 030 */
/* 031 */
/* 032 */     mutableStateArray_0[0].write(0, 0L);
/* 033 */     return (mutableStateArray_0[0].getRow());
/* 034 */   }
/* 035 */
/* 036 */
/* 037 */ }

12 Jul 2022 14:46:14,249 Executor task launch worker for task 197.0 in stage 10.0 (TID 1003) - code for input[0, string, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 64);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     UTF8String value_0 = isNull_0 ?
/* 033 */     null : (i.getUTF8String(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

12 Jul 2022 14:46:14,249 Executor task launch worker for task 197.0 in stage 10.0 (TID 1003) - Task 1003 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@4a523fb3
12 Jul 2022 14:46:14,249 Executor task launch worker for task 197.0 in stage 10.0 (TID 1003) - code for input[0, bigint, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     long value_0 = isNull_0 ?
/* 033 */     -1L : (i.getLong(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

12 Jul 2022 14:46:14,249 Executor task launch worker for task 197.0 in stage 10.0 (TID 1003) - Task 1003 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@4a523fb3
12 Jul 2022 14:46:14,249 Executor task launch worker for task 197.0 in stage 10.0 (TID 1003) - Writing shuffle index file for mapId 1003 with length 1
12 Jul 2022 14:46:14,250 Executor task launch worker for task 197.0 in stage 10.0 (TID 1003) - Shuffle index for mapId 1003: [0]
12 Jul 2022 14:46:14,250 Executor task launch worker for task 197.0 in stage 10.0 (TID 1003) - Finished task 197.0 in stage 10.0 (TID 1003). 3956 bytes result sent to driver
12 Jul 2022 14:46:14,250 Executor task launch worker for task 197.0 in stage 10.0 (TID 1003) - removing (10, 0) from stageTCMP
12 Jul 2022 14:46:14,250 dispatcher-event-loop-0 - parentName: , name: TaskSet_10.0, runningTasks: 0
12 Jul 2022 14:46:14,250 dispatcher-event-loop-0 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
12 Jul 2022 14:46:14,250 dispatcher-event-loop-0 - Moving to ANY after waiting for 0ms
12 Jul 2022 14:46:14,250 dispatcher-event-loop-0 - Starting task 198.0 in stage 10.0 (TID 1004) (MTD-Minhnx12, executor driver, partition 198, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
12 Jul 2022 14:46:14,250 task-result-getter-3 - Finished task 197.0 in stage 10.0 (TID 1003) in 5 ms on MTD-Minhnx12 (executor driver) (198/200)
12 Jul 2022 14:46:14,250 Executor task launch worker for task 198.0 in stage 10.0 (TID 1004) - Running task 198.0 in stage 10.0 (TID 1004)
12 Jul 2022 14:46:14,251 Executor task launch worker for task 198.0 in stage 10.0 (TID 1004) - stageTCMP: (10, 0) -> 1
12 Jul 2022 14:46:14,251 dag-scheduler-event-loop - ShuffleMapTask finished on driver
12 Jul 2022 14:46:14,252 Executor task launch worker for task 198.0 in stage 10.0 (TID 1004) - Fetching outputs for shuffle 6
12 Jul 2022 14:46:14,252 Executor task launch worker for task 198.0 in stage 10.0 (TID 1004) - Convert map statuses for shuffle 6, mappers 0-1, partitions 198-199
12 Jul 2022 14:46:14,252 Executor task launch worker for task 198.0 in stage 10.0 (TID 1004) - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
12 Jul 2022 14:46:14,252 Executor task launch worker for task 198.0 in stage 10.0 (TID 1004) - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
12 Jul 2022 14:46:14,252 Executor task launch worker for task 198.0 in stage 10.0 (TID 1004) - Started 0 remote fetches in 0 ms
12 Jul 2022 14:46:14,252 Executor task launch worker for task 198.0 in stage 10.0 (TID 1004) - Start fetching local blocks: 
12 Jul 2022 14:46:14,252 Executor task launch worker for task 198.0 in stage 10.0 (TID 1004) - Got local blocks in 0 ms
12 Jul 2022 14:46:14,253 Executor task launch worker for task 198.0 in stage 10.0 (TID 1004) - code for 0:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */
/* 030 */
/* 031 */
/* 032 */     mutableStateArray_0[0].write(0, 0L);
/* 033 */     return (mutableStateArray_0[0].getRow());
/* 034 */   }
/* 035 */
/* 036 */
/* 037 */ }

12 Jul 2022 14:46:14,253 Executor task launch worker for task 198.0 in stage 10.0 (TID 1004) - code for input[0, string, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 64);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     UTF8String value_0 = isNull_0 ?
/* 033 */     null : (i.getUTF8String(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

12 Jul 2022 14:46:14,253 Executor task launch worker for task 198.0 in stage 10.0 (TID 1004) - Task 1004 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@5c86fcce
12 Jul 2022 14:46:14,254 Executor task launch worker for task 198.0 in stage 10.0 (TID 1004) - code for input[0, bigint, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     long value_0 = isNull_0 ?
/* 033 */     -1L : (i.getLong(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

12 Jul 2022 14:46:14,254 Executor task launch worker for task 198.0 in stage 10.0 (TID 1004) - Task 1004 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@5c86fcce
12 Jul 2022 14:46:14,254 Executor task launch worker for task 198.0 in stage 10.0 (TID 1004) - Writing shuffle index file for mapId 1004 with length 1
12 Jul 2022 14:46:14,254 Executor task launch worker for task 198.0 in stage 10.0 (TID 1004) - Shuffle index for mapId 1004: [0]
12 Jul 2022 14:46:14,254 Executor task launch worker for task 198.0 in stage 10.0 (TID 1004) - Finished task 198.0 in stage 10.0 (TID 1004). 3956 bytes result sent to driver
12 Jul 2022 14:46:14,254 Executor task launch worker for task 198.0 in stage 10.0 (TID 1004) - removing (10, 0) from stageTCMP
12 Jul 2022 14:46:14,254 dispatcher-event-loop-0 - parentName: , name: TaskSet_10.0, runningTasks: 0
12 Jul 2022 14:46:14,255 dispatcher-event-loop-0 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
12 Jul 2022 14:46:14,255 dispatcher-event-loop-0 - Moving to ANY after waiting for 0ms
12 Jul 2022 14:46:14,255 dispatcher-event-loop-0 - Starting task 199.0 in stage 10.0 (TID 1005) (MTD-Minhnx12, executor driver, partition 199, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
12 Jul 2022 14:46:14,255 Executor task launch worker for task 199.0 in stage 10.0 (TID 1005) - Running task 199.0 in stage 10.0 (TID 1005)
12 Jul 2022 14:46:14,255 task-result-getter-0 - Finished task 198.0 in stage 10.0 (TID 1004) in 5 ms on MTD-Minhnx12 (executor driver) (199/200)
12 Jul 2022 14:46:14,255 Executor task launch worker for task 199.0 in stage 10.0 (TID 1005) - stageTCMP: (10, 0) -> 1
12 Jul 2022 14:46:14,255 dag-scheduler-event-loop - ShuffleMapTask finished on driver
12 Jul 2022 14:46:14,256 Executor task launch worker for task 199.0 in stage 10.0 (TID 1005) - Fetching outputs for shuffle 6
12 Jul 2022 14:46:14,256 Executor task launch worker for task 199.0 in stage 10.0 (TID 1005) - Convert map statuses for shuffle 6, mappers 0-1, partitions 199-200
12 Jul 2022 14:46:14,256 Executor task launch worker for task 199.0 in stage 10.0 (TID 1005) - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
12 Jul 2022 14:46:14,257 Executor task launch worker for task 199.0 in stage 10.0 (TID 1005) - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
12 Jul 2022 14:46:14,257 Executor task launch worker for task 199.0 in stage 10.0 (TID 1005) - Started 0 remote fetches in 0 ms
12 Jul 2022 14:46:14,257 Executor task launch worker for task 199.0 in stage 10.0 (TID 1005) - Start fetching local blocks: 
12 Jul 2022 14:46:14,257 Executor task launch worker for task 199.0 in stage 10.0 (TID 1005) - Got local blocks in 0 ms
12 Jul 2022 14:46:14,257 Executor task launch worker for task 199.0 in stage 10.0 (TID 1005) - code for 0:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */
/* 030 */
/* 031 */
/* 032 */     mutableStateArray_0[0].write(0, 0L);
/* 033 */     return (mutableStateArray_0[0].getRow());
/* 034 */   }
/* 035 */
/* 036 */
/* 037 */ }

12 Jul 2022 14:46:14,258 Executor task launch worker for task 199.0 in stage 10.0 (TID 1005) - code for input[0, string, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 64);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     UTF8String value_0 = isNull_0 ?
/* 033 */     null : (i.getUTF8String(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

12 Jul 2022 14:46:14,258 Executor task launch worker for task 199.0 in stage 10.0 (TID 1005) - Task 1005 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@12f2cdd4
12 Jul 2022 14:46:14,258 Executor task launch worker for task 199.0 in stage 10.0 (TID 1005) - code for input[0, bigint, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     long value_0 = isNull_0 ?
/* 033 */     -1L : (i.getLong(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

12 Jul 2022 14:46:14,258 Executor task launch worker for task 199.0 in stage 10.0 (TID 1005) - Task 1005 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@12f2cdd4
12 Jul 2022 14:46:14,258 Executor task launch worker for task 199.0 in stage 10.0 (TID 1005) - Writing shuffle index file for mapId 1005 with length 1
12 Jul 2022 14:46:14,258 Executor task launch worker for task 199.0 in stage 10.0 (TID 1005) - Shuffle index for mapId 1005: [0]
12 Jul 2022 14:46:14,259 Executor task launch worker for task 199.0 in stage 10.0 (TID 1005) - Finished task 199.0 in stage 10.0 (TID 1005). 3956 bytes result sent to driver
12 Jul 2022 14:46:14,259 Executor task launch worker for task 199.0 in stage 10.0 (TID 1005) - removing (10, 0) from stageTCMP
12 Jul 2022 14:46:14,259 dispatcher-event-loop-0 - parentName: , name: TaskSet_10.0, runningTasks: 0
12 Jul 2022 14:46:14,259 dispatcher-event-loop-0 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
12 Jul 2022 14:46:14,259 dispatcher-event-loop-0 - No tasks for locality level NO_PREF, so moving to locality level ANY
12 Jul 2022 14:46:14,259 task-result-getter-1 - Finished task 199.0 in stage 10.0 (TID 1005) in 4 ms on MTD-Minhnx12 (executor driver) (200/200)
12 Jul 2022 14:46:14,259 task-result-getter-1 - Removed TaskSet 10.0, whose tasks have all completed, from pool 
12 Jul 2022 14:46:14,259 dag-scheduler-event-loop - ShuffleMapTask finished on driver
12 Jul 2022 14:46:14,259 dag-scheduler-event-loop - ShuffleMapStage 10 (parquet at Main.java:37) finished in 1.181 s
12 Jul 2022 14:46:14,259 dag-scheduler-event-loop - looking for newly runnable stages
12 Jul 2022 14:46:14,259 dag-scheduler-event-loop - running: Set()
12 Jul 2022 14:46:14,259 dag-scheduler-event-loop - waiting: Set(ResultStage 11)
12 Jul 2022 14:46:14,259 dag-scheduler-event-loop - failed: Set()
12 Jul 2022 14:46:14,260 dag-scheduler-event-loop - Increasing epoch to 8
12 Jul 2022 14:46:14,260 dag-scheduler-event-loop - submitStage(ResultStage 11 (name=parquet at Main.java:37;jobs=3))
12 Jul 2022 14:46:14,260 dag-scheduler-event-loop - missing: List()
12 Jul 2022 14:46:14,260 dag-scheduler-event-loop - Submitting ResultStage 11 (ShuffledRowRDD[35] at parquet at Main.java:37), which has no missing parents
12 Jul 2022 14:46:14,260 dag-scheduler-event-loop - submitMissingTasks(ResultStage 11)
12 Jul 2022 14:46:14,273 dag-scheduler-event-loop - Block broadcast_14 stored as values in memory (estimated size 168.9 KiB, free 1387.2 MiB)
12 Jul 2022 14:46:14,273 dag-scheduler-event-loop - Put block broadcast_14 locally took 0 ms
12 Jul 2022 14:46:14,273 dag-scheduler-event-loop - Putting block broadcast_14 without replication took 0 ms
12 Jul 2022 14:46:14,275 dag-scheduler-event-loop - Block broadcast_14_piece0 stored as bytes in memory (estimated size 59.8 KiB, free 1387.1 MiB)
12 Jul 2022 14:46:14,275 dispatcher-BlockManagerMaster - Updating block info on master broadcast_14_piece0 for BlockManagerId(driver, MTD-Minhnx12, 35671, None)
12 Jul 2022 14:46:14,275 dispatcher-BlockManagerMaster - Added broadcast_14_piece0 in memory on MTD-Minhnx12:35671 (size: 59.8 KiB, free: 1388.0 MiB)
12 Jul 2022 14:46:14,275 dag-scheduler-event-loop - Updated info of block broadcast_14_piece0
12 Jul 2022 14:46:14,275 dag-scheduler-event-loop - Told master about block broadcast_14_piece0
12 Jul 2022 14:46:14,275 dag-scheduler-event-loop - Put block broadcast_14_piece0 locally took 0 ms
12 Jul 2022 14:46:14,275 dag-scheduler-event-loop - Putting block broadcast_14_piece0 without replication took 0 ms
12 Jul 2022 14:46:14,276 dag-scheduler-event-loop - Created broadcast 14 from broadcast at DAGScheduler.scala:1383
12 Jul 2022 14:46:14,276 dag-scheduler-event-loop - Submitting 1 missing tasks from ResultStage 11 (ShuffledRowRDD[35] at parquet at Main.java:37) (first 15 tasks are for partitions Vector(0))
12 Jul 2022 14:46:14,276 dag-scheduler-event-loop - Adding task set 11.0 with 1 tasks resource profile 0
12 Jul 2022 14:46:14,276 dag-scheduler-event-loop - Epoch for TaskSet 11.0: 8
12 Jul 2022 14:46:14,276 dag-scheduler-event-loop - Adding pending tasks took 0 ms
12 Jul 2022 14:46:14,276 dag-scheduler-event-loop - Valid locality levels for TaskSet 11.0: NODE_LOCAL, ANY
12 Jul 2022 14:46:14,276 dispatcher-event-loop-1 - parentName: , name: TaskSet_11.0, runningTasks: 0
12 Jul 2022 14:46:14,276 dispatcher-event-loop-1 - Starting task 0.0 in stage 11.0 (TID 1006) (MTD-Minhnx12, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
12 Jul 2022 14:46:14,277 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - Running task 0.0 in stage 11.0 (TID 1006)
12 Jul 2022 14:46:14,277 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - stageTCMP: (11, 0) -> 1
12 Jul 2022 14:46:14,277 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - Getting local block broadcast_14
12 Jul 2022 14:46:14,277 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - Level for block broadcast_14 is StorageLevel(disk, memory, deserialized, 1 replicas)
12 Jul 2022 14:46:14,287 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - Fetching outputs for shuffle 7
12 Jul 2022 14:46:14,287 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - Convert map statuses for shuffle 7, mappers 0-200, partitions 0-1
12 Jul 2022 14:46:14,287 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
12 Jul 2022 14:46:14,288 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - Getting 92 (15.0 KiB) non-empty blocks including 92 (15.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
12 Jul 2022 14:46:14,288 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - Started 0 remote fetches in 0 ms
12 Jul 2022 14:46:14,288 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - Start fetching local blocks: (shuffle_7_806_0,1), (shuffle_7_807_0,5), (shuffle_7_808_0,7), (shuffle_7_809_0,9), (shuffle_7_810_0,15), (shuffle_7_811_0,17), (shuffle_7_812_0,23), (shuffle_7_813_0,24), (shuffle_7_814_0,25), (shuffle_7_815_0,26), (shuffle_7_816_0,27), (shuffle_7_817_0,28), (shuffle_7_818_0,30), (shuffle_7_819_0,31), (shuffle_7_820_0,32), (shuffle_7_821_0,33), (shuffle_7_822_0,38), (shuffle_7_823_0,39), (shuffle_7_824_0,41), (shuffle_7_825_0,42), (shuffle_7_826_0,45), (shuffle_7_827_0,48), (shuffle_7_828_0,55), (shuffle_7_829_0,57), (shuffle_7_830_0,61), (shuffle_7_831_0,62), (shuffle_7_832_0,64), (shuffle_7_833_0,65), (shuffle_7_834_0,66), (shuffle_7_835_0,70), (shuffle_7_836_0,73), (shuffle_7_837_0,75), (shuffle_7_838_0,76), (shuffle_7_839_0,80), (shuffle_7_840_0,81), (shuffle_7_841_0,82), (shuffle_7_842_0,84), (shuffle_7_843_0,85), (shuffle_7_844_0,86), (shuffle_7_845_0,88), (shuffle_7_846_0,90), (shuffle_7_847_0,91), (shuffle_7_848_0,93), (shuffle_7_849_0,94), (shuffle_7_850_0,96), (shuffle_7_851_0,99), (shuffle_7_852_0,100), (shuffle_7_853_0,102), (shuffle_7_854_0,103), (shuffle_7_855_0,104), (shuffle_7_856_0,105), (shuffle_7_857_0,106), (shuffle_7_858_0,108), (shuffle_7_859_0,110), (shuffle_7_860_0,113), (shuffle_7_861_0,114), (shuffle_7_862_0,116), (shuffle_7_863_0,117), (shuffle_7_864_0,120), (shuffle_7_865_0,121), (shuffle_7_866_0,122), (shuffle_7_867_0,124), (shuffle_7_868_0,125), (shuffle_7_869_0,129), (shuffle_7_870_0,131), (shuffle_7_871_0,132), (shuffle_7_872_0,133), (shuffle_7_873_0,137), (shuffle_7_874_0,139), (shuffle_7_875_0,140), (shuffle_7_876_0,141), (shuffle_7_877_0,142), (shuffle_7_878_0,145), (shuffle_7_879_0,146), (shuffle_7_880_0,148), (shuffle_7_881_0,149), (shuffle_7_882_0,153), (shuffle_7_883_0,156), (shuffle_7_884_0,160), (shuffle_7_885_0,162), (shuffle_7_886_0,163), (shuffle_7_887_0,165), (shuffle_7_888_0,170), (shuffle_7_889_0,177), (shuffle_7_890_0,178), (shuffle_7_891_0,181), (shuffle_7_892_0,182), (shuffle_7_893_0,183), (shuffle_7_894_0,189), (shuffle_7_895_0,190), (shuffle_7_896_0,193), (shuffle_7_897_0,194)
12 Jul 2022 14:46:14,288 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - Getting local shuffle block shuffle_7_806_0
12 Jul 2022 14:46:14,288 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - Getting local shuffle block shuffle_7_807_0
12 Jul 2022 14:46:14,289 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - Getting local shuffle block shuffle_7_808_0
12 Jul 2022 14:46:14,289 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - Getting local shuffle block shuffle_7_809_0
12 Jul 2022 14:46:14,289 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - Getting local shuffle block shuffle_7_810_0
12 Jul 2022 14:46:14,289 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - Getting local shuffle block shuffle_7_811_0
12 Jul 2022 14:46:14,289 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - Getting local shuffle block shuffle_7_812_0
12 Jul 2022 14:46:14,289 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - Getting local shuffle block shuffle_7_813_0
12 Jul 2022 14:46:14,289 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - Getting local shuffle block shuffle_7_814_0
12 Jul 2022 14:46:14,289 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - Getting local shuffle block shuffle_7_815_0
12 Jul 2022 14:46:14,289 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - Getting local shuffle block shuffle_7_816_0
12 Jul 2022 14:46:14,289 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - Getting local shuffle block shuffle_7_817_0
12 Jul 2022 14:46:14,290 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - Getting local shuffle block shuffle_7_818_0
12 Jul 2022 14:46:14,290 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - Getting local shuffle block shuffle_7_819_0
12 Jul 2022 14:46:14,290 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - Getting local shuffle block shuffle_7_820_0
12 Jul 2022 14:46:14,290 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - Getting local shuffle block shuffle_7_821_0
12 Jul 2022 14:46:14,290 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - Getting local shuffle block shuffle_7_822_0
12 Jul 2022 14:46:14,290 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - Getting local shuffle block shuffle_7_823_0
12 Jul 2022 14:46:14,290 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - Getting local shuffle block shuffle_7_824_0
12 Jul 2022 14:46:14,290 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - Getting local shuffle block shuffle_7_825_0
12 Jul 2022 14:46:14,290 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - Getting local shuffle block shuffle_7_826_0
12 Jul 2022 14:46:14,290 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - Getting local shuffle block shuffle_7_827_0
12 Jul 2022 14:46:14,290 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - Getting local shuffle block shuffle_7_828_0
12 Jul 2022 14:46:14,291 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - Getting local shuffle block shuffle_7_829_0
12 Jul 2022 14:46:14,291 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - Getting local shuffle block shuffle_7_830_0
12 Jul 2022 14:46:14,291 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - Getting local shuffle block shuffle_7_831_0
12 Jul 2022 14:46:14,291 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - Getting local shuffle block shuffle_7_832_0
12 Jul 2022 14:46:14,291 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - Getting local shuffle block shuffle_7_833_0
12 Jul 2022 14:46:14,291 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - Getting local shuffle block shuffle_7_834_0
12 Jul 2022 14:46:14,291 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - Getting local shuffle block shuffle_7_835_0
12 Jul 2022 14:46:14,291 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - Getting local shuffle block shuffle_7_836_0
12 Jul 2022 14:46:14,291 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - Getting local shuffle block shuffle_7_837_0
12 Jul 2022 14:46:14,291 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - Getting local shuffle block shuffle_7_838_0
12 Jul 2022 14:46:14,291 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - Getting local shuffle block shuffle_7_839_0
12 Jul 2022 14:46:14,291 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - Getting local shuffle block shuffle_7_840_0
12 Jul 2022 14:46:14,292 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - Getting local shuffle block shuffle_7_841_0
12 Jul 2022 14:46:14,292 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - Getting local shuffle block shuffle_7_842_0
12 Jul 2022 14:46:14,292 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - Getting local shuffle block shuffle_7_843_0
12 Jul 2022 14:46:14,292 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - Getting local shuffle block shuffle_7_844_0
12 Jul 2022 14:46:14,292 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - Getting local shuffle block shuffle_7_845_0
12 Jul 2022 14:46:14,292 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - Getting local shuffle block shuffle_7_846_0
12 Jul 2022 14:46:14,292 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - Getting local shuffle block shuffle_7_847_0
12 Jul 2022 14:46:14,292 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - Getting local shuffle block shuffle_7_848_0
12 Jul 2022 14:46:14,292 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - Getting local shuffle block shuffle_7_849_0
12 Jul 2022 14:46:14,292 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - Getting local shuffle block shuffle_7_850_0
12 Jul 2022 14:46:14,292 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - Getting local shuffle block shuffle_7_851_0
12 Jul 2022 14:46:14,292 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - Getting local shuffle block shuffle_7_852_0
12 Jul 2022 14:46:14,293 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - Getting local shuffle block shuffle_7_853_0
12 Jul 2022 14:46:14,293 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - Getting local shuffle block shuffle_7_854_0
12 Jul 2022 14:46:14,293 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - Getting local shuffle block shuffle_7_855_0
12 Jul 2022 14:46:14,293 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - Getting local shuffle block shuffle_7_856_0
12 Jul 2022 14:46:14,293 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - Getting local shuffle block shuffle_7_857_0
12 Jul 2022 14:46:14,293 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - Getting local shuffle block shuffle_7_858_0
12 Jul 2022 14:46:14,293 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - Getting local shuffle block shuffle_7_859_0
12 Jul 2022 14:46:14,293 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - Getting local shuffle block shuffle_7_860_0
12 Jul 2022 14:46:14,293 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - Getting local shuffle block shuffle_7_861_0
12 Jul 2022 14:46:14,293 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - Getting local shuffle block shuffle_7_862_0
12 Jul 2022 14:46:14,293 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - Getting local shuffle block shuffle_7_863_0
12 Jul 2022 14:46:14,293 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - Getting local shuffle block shuffle_7_864_0
12 Jul 2022 14:46:14,293 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - Getting local shuffle block shuffle_7_865_0
12 Jul 2022 14:46:14,294 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - Getting local shuffle block shuffle_7_866_0
12 Jul 2022 14:46:14,294 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - Getting local shuffle block shuffle_7_867_0
12 Jul 2022 14:46:14,294 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - Getting local shuffle block shuffle_7_868_0
12 Jul 2022 14:46:14,294 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - Getting local shuffle block shuffle_7_869_0
12 Jul 2022 14:46:14,294 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - Getting local shuffle block shuffle_7_870_0
12 Jul 2022 14:46:14,294 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - Getting local shuffle block shuffle_7_871_0
12 Jul 2022 14:46:14,294 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - Getting local shuffle block shuffle_7_872_0
12 Jul 2022 14:46:14,294 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - Getting local shuffle block shuffle_7_873_0
12 Jul 2022 14:46:14,294 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - Getting local shuffle block shuffle_7_874_0
12 Jul 2022 14:46:14,294 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - Getting local shuffle block shuffle_7_875_0
12 Jul 2022 14:46:14,294 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - Getting local shuffle block shuffle_7_876_0
12 Jul 2022 14:46:14,294 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - Getting local shuffle block shuffle_7_877_0
12 Jul 2022 14:46:14,294 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - Getting local shuffle block shuffle_7_878_0
12 Jul 2022 14:46:14,295 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - Getting local shuffle block shuffle_7_879_0
12 Jul 2022 14:46:14,295 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - Getting local shuffle block shuffle_7_880_0
12 Jul 2022 14:46:14,295 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - Getting local shuffle block shuffle_7_881_0
12 Jul 2022 14:46:14,295 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - Getting local shuffle block shuffle_7_882_0
12 Jul 2022 14:46:14,295 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - Getting local shuffle block shuffle_7_883_0
12 Jul 2022 14:46:14,295 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - Getting local shuffle block shuffle_7_884_0
12 Jul 2022 14:46:14,295 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - Getting local shuffle block shuffle_7_885_0
12 Jul 2022 14:46:14,295 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - Getting local shuffle block shuffle_7_886_0
12 Jul 2022 14:46:14,295 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - Getting local shuffle block shuffle_7_887_0
12 Jul 2022 14:46:14,295 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - Getting local shuffle block shuffle_7_888_0
12 Jul 2022 14:46:14,295 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - Getting local shuffle block shuffle_7_889_0
12 Jul 2022 14:46:14,295 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - Getting local shuffle block shuffle_7_890_0
12 Jul 2022 14:46:14,295 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - Getting local shuffle block shuffle_7_891_0
12 Jul 2022 14:46:14,296 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - Getting local shuffle block shuffle_7_892_0
12 Jul 2022 14:46:14,296 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - Getting local shuffle block shuffle_7_893_0
12 Jul 2022 14:46:14,296 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - Getting local shuffle block shuffle_7_894_0
12 Jul 2022 14:46:14,296 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - Getting local shuffle block shuffle_7_895_0
12 Jul 2022 14:46:14,296 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - Getting local shuffle block shuffle_7_896_0
12 Jul 2022 14:46:14,296 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - Getting local shuffle block shuffle_7_897_0
12 Jul 2022 14:46:14,296 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - Got local blocks in 8 ms
12 Jul 2022 14:46:14,297 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - Instantiating committer FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202207121446121289673628777682569_0011}; taskId=attempt_202207121446121289673628777682569_0011_m_000000_1006, status=''}; org.apache.parquet.hadoop.ParquetOutputCommitter@9bca93f}; outputPath=null, workPath=null, algorithmVersion=0, skipCleanup=false, ignoreCleanupFailures=false} with output path file:/home/minh/MasterDev/Task8/output/button_count_by_user_id_device_model and job context TaskAttemptContextImpl{JobContextImpl{jobId=job_202207121446121289673628777682569_0011}; taskId=attempt_202207121446121289673628777682569_0011_m_000000_1006, status=''}
12 Jul 2022 14:46:14,297 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - File Output Committer Algorithm version is 1
12 Jul 2022 14:46:14,297 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
12 Jul 2022 14:46:14,298 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
12 Jul 2022 14:46:14,298 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - Instantiating committer FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202207121446121289673628777682569_0011}; taskId=attempt_202207121446121289673628777682569_0011_m_000000_1006, status=''}; org.apache.parquet.hadoop.ParquetOutputCommitter@2858a3a7}; outputPath=null, workPath=null, algorithmVersion=0, skipCleanup=false, ignoreCleanupFailures=false} with output path file:/home/minh/MasterDev/Task8/output/button_count_by_user_id_device_model and job context TaskAttemptContextImpl{JobContextImpl{jobId=job_202207121446121289673628777682569_0011}; taskId=attempt_202207121446121289673628777682569_0011_m_000000_1006, status=''}
12 Jul 2022 14:46:14,298 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - File Output Committer Algorithm version is 1
12 Jul 2022 14:46:14,298 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
12 Jul 2022 14:46:14,298 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
12 Jul 2022 14:46:14,298 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - Compression: SNAPPY
12 Jul 2022 14:46:14,299 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - Compression: SNAPPY
12 Jul 2022 14:46:14,299 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - Parquet block size to 134217728
12 Jul 2022 14:46:14,299 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - Parquet page size to 1048576
12 Jul 2022 14:46:14,299 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - Parquet dictionary page size to 1048576
12 Jul 2022 14:46:14,299 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - Dictionary is on
12 Jul 2022 14:46:14,299 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - Validation is off
12 Jul 2022 14:46:14,299 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - Writer version is: PARQUET_1_0
12 Jul 2022 14:46:14,299 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - Maximum row group padding size is 8388608 bytes
12 Jul 2022 14:46:14,299 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - Page size checking is: estimated
12 Jul 2022 14:46:14,299 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - Min row count for page size check is: 100
12 Jul 2022 14:46:14,299 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - Max row count for page size check is: 10000
12 Jul 2022 14:46:14,300 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "user_id_device_model",
    "type" : "string",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "button_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "count",
    "type" : "long",
    "nullable" : false,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required binary user_id_device_model (UTF8);
  optional binary button_id (UTF8);
  required int64 count;
}

       
12 Jul 2022 14:46:14,308 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - 0: start
12 Jul 2022 14:46:14,309 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - Got recycled compressor
12 Jul 2022 14:46:14,309 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - initial slab of size 1024
12 Jul 2022 14:46:14,309 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - Encoding: RunLengthBitPackingHybridEncoder with bithWidth: 1 initialCapacity 64
12 Jul 2022 14:46:14,309 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - initial slab of size 64
12 Jul 2022 14:46:14,309 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - initial slab of size 1024
12 Jul 2022 14:46:14,309 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - initial slab of size 1024
12 Jul 2022 14:46:14,309 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - Adjust block size from 134,217,728 to 134,217,728 for writer: org.apache.parquet.hadoop.InternalParquetRecordWriter@33c0bb9c
12 Jul 2022 14:46:14,310 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - <!-- start message -->
12 Jul 2022 14:46:14,310 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - < MESSAGE START >
12 Jul 2022 14:46:14,310 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - 0, VistedIndex{vistedIndexes={}}: [] r:0
12 Jul 2022 14:46:14,310 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - <user_id_device_model>
12 Jul 2022 14:46:14,310 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - startField(user_id_device_model, 0)
12 Jul 2022 14:46:14,310 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - 0, VistedIndex{vistedIndexes={}}: [user_id_device_model] r:0
12 Jul 2022 14:46:14,310 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - [53, 102, 102, 49, 50, 102, 99, 51, 45, 48, 97, 50, 99, 45, 52, 55, 49, 53, 45, 56, 100, 99, 98, 45, 52, 101, 53, 52, 48, 97, 54, 101, 52, 99, 50, 54, 95, 115, 97, 109, 115, 117, 110, 103, 32, 47, 32, 83, 77, 45, 71, 54, 49, 48, 70]
12 Jul 2022 14:46:14,310 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - addBinary(55 bytes)
12 Jul 2022 14:46:14,310 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - r: 0
12 Jul 2022 14:46:14,310 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - 0, VistedIndex{vistedIndexes={}}: [user_id_device_model] r:0
12 Jul 2022 14:46:14,310 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - </user_id_device_model>
12 Jul 2022 14:46:14,310 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - endField(user_id_device_model, 0)
12 Jul 2022 14:46:14,310 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - 0, VistedIndex{vistedIndexes={0}}: [] r:0
12 Jul 2022 14:46:14,310 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - <button_id>
12 Jul 2022 14:46:14,310 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - startField(button_id, 1)
12 Jul 2022 14:46:14,310 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - 0, VistedIndex{vistedIndexes={0}}: [button_id] r:0
12 Jul 2022 14:46:14,310 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - [115, 101, 97, 108, 95, 100, 101, 97, 108, 95, 118, 105, 101, 119, 95, 100, 101, 115, 101, 108, 101, 99, 116, 95, 115, 101, 108, 101, 99, 116, 95, 119, 101, 105, 103, 104, 116]
12 Jul 2022 14:46:14,310 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - addBinary(37 bytes)
12 Jul 2022 14:46:14,310 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - r: 0
12 Jul 2022 14:46:14,310 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - 0, VistedIndex{vistedIndexes={0}}: [button_id] r:0
12 Jul 2022 14:46:14,310 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - </button_id>
12 Jul 2022 14:46:14,310 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - endField(button_id, 1)
12 Jul 2022 14:46:14,310 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - 0, VistedIndex{vistedIndexes={0, 1}}: [] r:0
12 Jul 2022 14:46:14,310 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - <count>
12 Jul 2022 14:46:14,310 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - startField(count, 2)
12 Jul 2022 14:46:14,310 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - 0, VistedIndex{vistedIndexes={0, 1}}: [count] r:0
12 Jul 2022 14:46:14,310 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - 1
12 Jul 2022 14:46:14,310 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - addLong(1)
12 Jul 2022 14:46:14,310 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - r: 0
12 Jul 2022 14:46:14,310 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - 0, VistedIndex{vistedIndexes={0, 1}}: [count] r:0
12 Jul 2022 14:46:14,310 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - </count>
12 Jul 2022 14:46:14,310 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - endField(count, 2)
12 Jul 2022 14:46:14,310 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - 0, VistedIndex{vistedIndexes={0, 1, 2}}: [] r:0
12 Jul 2022 14:46:14,310 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - < MESSAGE END >
12 Jul 2022 14:46:14,310 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - 0, VistedIndex{vistedIndexes={0, 1, 2}}: [] r:0
12 Jul 2022 14:46:14,310 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - <!-- end message -->
12 Jul 2022 14:46:14,311 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - <!-- start message -->
12 Jul 2022 14:46:14,311 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - < MESSAGE START >
12 Jul 2022 14:46:14,311 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - 0, VistedIndex{vistedIndexes={}}: [] r:0
12 Jul 2022 14:46:14,311 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - <user_id_device_model>
12 Jul 2022 14:46:14,311 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - startField(user_id_device_model, 0)
12 Jul 2022 14:46:14,311 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - 0, VistedIndex{vistedIndexes={}}: [user_id_device_model] r:0
12 Jul 2022 14:46:14,311 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - [53, 99, 98, 98, 48, 102, 102, 97, 45, 102, 57, 53, 48, 45, 52, 52, 54, 102, 45, 98, 56, 99, 53, 45, 52, 97, 54, 102, 48, 97, 48, 97, 48, 50, 49, 48, 95, 105, 80, 104, 111, 110, 101]
12 Jul 2022 14:46:14,311 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - addBinary(43 bytes)
12 Jul 2022 14:46:14,311 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - r: 0
12 Jul 2022 14:46:14,311 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - 0, VistedIndex{vistedIndexes={}}: [user_id_device_model] r:0
12 Jul 2022 14:46:14,311 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - </user_id_device_model>
12 Jul 2022 14:46:14,311 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - endField(user_id_device_model, 0)
12 Jul 2022 14:46:14,311 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - 0, VistedIndex{vistedIndexes={0}}: [] r:0
12 Jul 2022 14:46:14,311 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - <button_id>
12 Jul 2022 14:46:14,311 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - startField(button_id, 1)
12 Jul 2022 14:46:14,311 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - 0, VistedIndex{vistedIndexes={0}}: [button_id] r:0
12 Jul 2022 14:46:14,311 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - [99, 104, 97, 116, 95, 112, 107, 103, 95, 115, 111, 115, 95, 112, 105, 99, 107, 117, 112]
12 Jul 2022 14:46:14,311 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - addBinary(19 bytes)
12 Jul 2022 14:46:14,311 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - r: 0
12 Jul 2022 14:46:14,311 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - 0, VistedIndex{vistedIndexes={0}}: [button_id] r:0
12 Jul 2022 14:46:14,311 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - </button_id>
12 Jul 2022 14:46:14,311 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - endField(button_id, 1)
12 Jul 2022 14:46:14,311 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - 0, VistedIndex{vistedIndexes={0, 1}}: [] r:0
12 Jul 2022 14:46:14,311 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - <count>
12 Jul 2022 14:46:14,311 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - startField(count, 2)
12 Jul 2022 14:46:14,311 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - 0, VistedIndex{vistedIndexes={0, 1}}: [count] r:0
12 Jul 2022 14:46:14,311 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - 1
12 Jul 2022 14:46:14,311 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - addLong(1)
12 Jul 2022 14:46:14,311 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - r: 0
12 Jul 2022 14:46:14,311 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - 0, VistedIndex{vistedIndexes={0, 1}}: [count] r:0
12 Jul 2022 14:46:14,311 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - </count>
12 Jul 2022 14:46:14,311 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - endField(count, 2)
12 Jul 2022 14:46:14,311 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - 0, VistedIndex{vistedIndexes={0, 1, 2}}: [] r:0
12 Jul 2022 14:46:14,311 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - < MESSAGE END >
12 Jul 2022 14:46:14,311 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - 0, VistedIndex{vistedIndexes={0, 1, 2}}: [] r:0
12 Jul 2022 14:46:14,311 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - <!-- end message -->
12 Jul 2022 14:46:14,311 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - <!-- start message -->
12 Jul 2022 14:46:14,311 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - < MESSAGE START >
12 Jul 2022 14:46:14,311 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - 0, VistedIndex{vistedIndexes={}}: [] r:0
12 Jul 2022 14:46:14,311 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - <user_id_device_model>
12 Jul 2022 14:46:14,311 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - startField(user_id_device_model, 0)
12 Jul 2022 14:46:14,311 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - 0, VistedIndex{vistedIndexes={}}: [user_id_device_model] r:0
12 Jul 2022 14:46:14,311 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - [54, 48, 97, 98, 52, 100, 56, 54, 45, 51, 56, 53, 48, 45, 52, 101, 101, 56, 45, 56, 51, 55, 49, 45, 52, 100, 54, 52, 48, 97, 55, 56, 52, 99, 54, 56, 95, 115, 97, 109, 115, 117, 110, 103, 32, 47, 32, 83, 77, 45, 77, 50, 48, 53, 71]
12 Jul 2022 14:46:14,311 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - addBinary(55 bytes)
12 Jul 2022 14:46:14,311 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - r: 0
12 Jul 2022 14:46:14,311 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - 0, VistedIndex{vistedIndexes={}}: [user_id_device_model] r:0
12 Jul 2022 14:46:14,311 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - </user_id_device_model>
12 Jul 2022 14:46:14,311 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - endField(user_id_device_model, 0)
12 Jul 2022 14:46:14,311 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - 0, VistedIndex{vistedIndexes={0}}: [] r:0
12 Jul 2022 14:46:14,311 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - <button_id>
12 Jul 2022 14:46:14,311 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - startField(button_id, 1)
12 Jul 2022 14:46:14,311 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - 0, VistedIndex{vistedIndexes={0}}: [button_id] r:0
12 Jul 2022 14:46:14,311 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - [108, 105, 115, 116, 95, 99, 104, 97, 116, 95, 101, 110, 116, 101, 114, 95, 99, 104, 97, 110, 110, 101, 108, 95, 49]
12 Jul 2022 14:46:14,311 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - addBinary(25 bytes)
12 Jul 2022 14:46:14,311 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - r: 0
12 Jul 2022 14:46:14,311 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - 0, VistedIndex{vistedIndexes={0}}: [button_id] r:0
12 Jul 2022 14:46:14,311 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - </button_id>
12 Jul 2022 14:46:14,311 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - endField(button_id, 1)
12 Jul 2022 14:46:14,311 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - 0, VistedIndex{vistedIndexes={0, 1}}: [] r:0
12 Jul 2022 14:46:14,311 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - <count>
12 Jul 2022 14:46:14,311 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - startField(count, 2)
12 Jul 2022 14:46:14,311 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - 0, VistedIndex{vistedIndexes={0, 1}}: [count] r:0
12 Jul 2022 14:46:14,311 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - 1
12 Jul 2022 14:46:14,311 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - addLong(1)
12 Jul 2022 14:46:14,311 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - r: 0
12 Jul 2022 14:46:14,311 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - 0, VistedIndex{vistedIndexes={0, 1}}: [count] r:0
12 Jul 2022 14:46:14,311 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - </count>
12 Jul 2022 14:46:14,311 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - endField(count, 2)
12 Jul 2022 14:46:14,311 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - 0, VistedIndex{vistedIndexes={0, 1, 2}}: [] r:0
12 Jul 2022 14:46:14,311 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - < MESSAGE END >
12 Jul 2022 14:46:14,311 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - 0, VistedIndex{vistedIndexes={0, 1, 2}}: [] r:0
12 Jul 2022 14:46:14,311 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - <!-- end message -->
12 Jul 2022 14:46:14,311 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - <!-- start message -->
12 Jul 2022 14:46:14,311 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - < MESSAGE START >
12 Jul 2022 14:46:14,311 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - 0, VistedIndex{vistedIndexes={}}: [] r:0
12 Jul 2022 14:46:14,311 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - <user_id_device_model>
12 Jul 2022 14:46:14,311 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - startField(user_id_device_model, 0)
12 Jul 2022 14:46:14,311 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - 0, VistedIndex{vistedIndexes={}}: [user_id_device_model] r:0
12 Jul 2022 14:46:14,311 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - [53, 102, 50, 56, 99, 57, 50, 55, 45, 48, 54, 49, 56, 45, 52, 56, 49, 102, 45, 56, 56, 101, 101, 45, 52, 52, 51, 48, 48, 97, 54, 101, 52, 99, 52, 55, 95, 105, 80, 104, 111, 110, 101]
12 Jul 2022 14:46:14,311 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - addBinary(43 bytes)
12 Jul 2022 14:46:14,311 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - r: 0
12 Jul 2022 14:46:14,311 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - 0, VistedIndex{vistedIndexes={}}: [user_id_device_model] r:0
12 Jul 2022 14:46:14,311 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - </user_id_device_model>
12 Jul 2022 14:46:14,311 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - endField(user_id_device_model, 0)
12 Jul 2022 14:46:14,311 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - 0, VistedIndex{vistedIndexes={0}}: [] r:0
12 Jul 2022 14:46:14,311 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - <button_id>
12 Jul 2022 14:46:14,311 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - startField(button_id, 1)
12 Jul 2022 14:46:14,311 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - 0, VistedIndex{vistedIndexes={0}}: [button_id] r:0
12 Jul 2022 14:46:14,311 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - [111, 112, 101, 110, 95, 99, 114, 101, 97, 116, 101, 95, 111, 114, 100, 101, 114]
12 Jul 2022 14:46:14,311 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - addBinary(17 bytes)
12 Jul 2022 14:46:14,311 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - r: 0
12 Jul 2022 14:46:14,311 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - 0, VistedIndex{vistedIndexes={0}}: [button_id] r:0
12 Jul 2022 14:46:14,311 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - </button_id>
12 Jul 2022 14:46:14,311 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - endField(button_id, 1)
12 Jul 2022 14:46:14,311 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - 0, VistedIndex{vistedIndexes={0, 1}}: [] r:0
12 Jul 2022 14:46:14,311 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - <count>
12 Jul 2022 14:46:14,311 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - startField(count, 2)
12 Jul 2022 14:46:14,311 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - 0, VistedIndex{vistedIndexes={0, 1}}: [count] r:0
12 Jul 2022 14:46:14,311 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - 1
12 Jul 2022 14:46:14,311 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - addLong(1)
12 Jul 2022 14:46:14,311 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - r: 0
12 Jul 2022 14:46:14,311 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - 0, VistedIndex{vistedIndexes={0, 1}}: [count] r:0
12 Jul 2022 14:46:14,311 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - </count>
12 Jul 2022 14:46:14,311 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - endField(count, 2)
12 Jul 2022 14:46:14,312 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - 0, VistedIndex{vistedIndexes={0, 1, 2}}: [] r:0
12 Jul 2022 14:46:14,312 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - < MESSAGE END >
12 Jul 2022 14:46:14,312 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - 0, VistedIndex{vistedIndexes={0, 1, 2}}: [] r:0
12 Jul 2022 14:46:14,312 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - <!-- end message -->
12 Jul 2022 14:46:14,312 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - <!-- start message -->
12 Jul 2022 14:46:14,312 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - < MESSAGE START >
12 Jul 2022 14:46:14,312 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - 0, VistedIndex{vistedIndexes={}}: [] r:0
12 Jul 2022 14:46:14,312 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - <user_id_device_model>
12 Jul 2022 14:46:14,312 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - startField(user_id_device_model, 0)
12 Jul 2022 14:46:14,312 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - 0, VistedIndex{vistedIndexes={}}: [user_id_device_model] r:0
12 Jul 2022 14:46:14,312 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - [53, 102, 52, 48, 52, 54, 55, 49, 45, 102, 100, 57, 99, 45, 52, 57, 56, 98, 45, 57, 50, 50, 102, 45, 52, 48, 101, 98, 48, 97, 54, 101, 52, 99, 52, 56, 95, 105, 80, 104, 111, 110, 101]
12 Jul 2022 14:46:14,312 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - addBinary(43 bytes)
12 Jul 2022 14:46:14,312 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - r: 0
12 Jul 2022 14:46:14,312 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - 0, VistedIndex{vistedIndexes={}}: [user_id_device_model] r:0
12 Jul 2022 14:46:14,312 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - </user_id_device_model>
12 Jul 2022 14:46:14,312 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - endField(user_id_device_model, 0)
12 Jul 2022 14:46:14,312 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - 0, VistedIndex{vistedIndexes={0}}: [] r:0
12 Jul 2022 14:46:14,312 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - <button_id>
12 Jul 2022 14:46:14,312 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - startField(button_id, 1)
12 Jul 2022 14:46:14,312 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - 0, VistedIndex{vistedIndexes={0}}: [button_id] r:0
12 Jul 2022 14:46:14,312 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - [110, 111, 116, 105]
12 Jul 2022 14:46:14,312 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - addBinary(4 bytes)
12 Jul 2022 14:46:14,312 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - r: 0
12 Jul 2022 14:46:14,312 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - 0, VistedIndex{vistedIndexes={0}}: [button_id] r:0
12 Jul 2022 14:46:14,312 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - </button_id>
12 Jul 2022 14:46:14,312 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - endField(button_id, 1)
12 Jul 2022 14:46:14,312 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - 0, VistedIndex{vistedIndexes={0, 1}}: [] r:0
12 Jul 2022 14:46:14,312 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - <count>
12 Jul 2022 14:46:14,312 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - startField(count, 2)
12 Jul 2022 14:46:14,312 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - 0, VistedIndex{vistedIndexes={0, 1}}: [count] r:0
12 Jul 2022 14:46:14,312 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - 2
12 Jul 2022 14:46:14,312 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - addLong(2)
12 Jul 2022 14:46:14,312 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - r: 0
12 Jul 2022 14:46:14,312 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - 0, VistedIndex{vistedIndexes={0, 1}}: [count] r:0
12 Jul 2022 14:46:14,312 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - </count>
12 Jul 2022 14:46:14,312 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - endField(count, 2)
12 Jul 2022 14:46:14,312 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - 0, VistedIndex{vistedIndexes={0, 1, 2}}: [] r:0
12 Jul 2022 14:46:14,312 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - < MESSAGE END >
12 Jul 2022 14:46:14,312 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - 0, VistedIndex{vistedIndexes={0, 1, 2}}: [] r:0
12 Jul 2022 14:46:14,312 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - <!-- end message -->
12 Jul 2022 14:46:14,312 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - <!-- start message -->
12 Jul 2022 14:46:14,312 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - < MESSAGE START >
12 Jul 2022 14:46:14,312 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - 0, VistedIndex{vistedIndexes={}}: [] r:0
12 Jul 2022 14:46:14,312 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - <user_id_device_model>
12 Jul 2022 14:46:14,312 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - startField(user_id_device_model, 0)
12 Jul 2022 14:46:14,312 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - 0, VistedIndex{vistedIndexes={}}: [user_id_device_model] r:0
12 Jul 2022 14:46:14,312 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - [54, 48, 56, 102, 100, 48, 99, 51, 45, 52, 101, 56, 99, 45, 52, 51, 57, 99, 45, 57, 97, 53, 55, 45, 52, 98, 54, 101, 48, 97, 54, 101, 52, 99, 50, 52, 95, 105, 80, 104, 111, 110, 101]
12 Jul 2022 14:46:14,312 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - addBinary(43 bytes)
12 Jul 2022 14:46:14,312 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - r: 0
12 Jul 2022 14:46:14,312 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - 0, VistedIndex{vistedIndexes={}}: [user_id_device_model] r:0
12 Jul 2022 14:46:14,312 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - </user_id_device_model>
12 Jul 2022 14:46:14,312 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - endField(user_id_device_model, 0)
12 Jul 2022 14:46:14,312 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - 0, VistedIndex{vistedIndexes={0}}: [] r:0
12 Jul 2022 14:46:14,312 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - <button_id>
12 Jul 2022 14:46:14,312 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - startField(button_id, 1)
12 Jul 2022 14:46:14,312 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - 0, VistedIndex{vistedIndexes={0}}: [button_id] r:0
12 Jul 2022 14:46:14,312 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - [111, 114, 100, 101, 114, 115, 95, 116, 105, 99, 107, 101, 116, 95, 99, 114, 101, 97, 116, 101]
12 Jul 2022 14:46:14,312 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - addBinary(20 bytes)
12 Jul 2022 14:46:14,312 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - r: 0
12 Jul 2022 14:46:14,312 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - 0, VistedIndex{vistedIndexes={0}}: [button_id] r:0
12 Jul 2022 14:46:14,312 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - </button_id>
12 Jul 2022 14:46:14,312 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - endField(button_id, 1)
12 Jul 2022 14:46:14,312 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - 0, VistedIndex{vistedIndexes={0, 1}}: [] r:0
12 Jul 2022 14:46:14,312 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - <count>
12 Jul 2022 14:46:14,312 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - startField(count, 2)
12 Jul 2022 14:46:14,312 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - 0, VistedIndex{vistedIndexes={0, 1}}: [count] r:0
12 Jul 2022 14:46:14,312 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - 1
12 Jul 2022 14:46:14,312 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - addLong(1)
12 Jul 2022 14:46:14,312 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - r: 0
12 Jul 2022 14:46:14,312 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - 0, VistedIndex{vistedIndexes={0, 1}}: [count] r:0
12 Jul 2022 14:46:14,312 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - </count>
12 Jul 2022 14:46:14,312 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - endField(count, 2)
12 Jul 2022 14:46:14,312 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - 0, VistedIndex{vistedIndexes={0, 1, 2}}: [] r:0
12 Jul 2022 14:46:14,312 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - < MESSAGE END >
12 Jul 2022 14:46:14,312 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - 0, VistedIndex{vistedIndexes={0, 1, 2}}: [] r:0
12 Jul 2022 14:46:14,312 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - <!-- end message -->
12 Jul 2022 14:46:14,312 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - <!-- start message -->
12 Jul 2022 14:46:14,312 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - < MESSAGE START >
12 Jul 2022 14:46:14,312 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - 0, VistedIndex{vistedIndexes={}}: [] r:0
12 Jul 2022 14:46:14,312 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - <user_id_device_model>
12 Jul 2022 14:46:14,312 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - startField(user_id_device_model, 0)
12 Jul 2022 14:46:14,312 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - 0, VistedIndex{vistedIndexes={}}: [user_id_device_model] r:0
12 Jul 2022 14:46:14,312 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - [53, 102, 57, 97, 102, 57, 100, 49, 45, 51, 49, 49, 52, 45, 52, 55, 57, 57, 45, 97, 51, 97, 101, 45, 52, 52, 99, 98, 48, 97, 54, 101, 52, 99, 50, 54, 95, 105, 80, 104, 111, 110, 101]
12 Jul 2022 14:46:14,312 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - addBinary(43 bytes)
12 Jul 2022 14:46:14,312 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - r: 0
12 Jul 2022 14:46:14,312 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - 0, VistedIndex{vistedIndexes={}}: [user_id_device_model] r:0
12 Jul 2022 14:46:14,312 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - </user_id_device_model>
12 Jul 2022 14:46:14,312 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - endField(user_id_device_model, 0)
12 Jul 2022 14:46:14,312 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - 0, VistedIndex{vistedIndexes={0}}: [] r:0
12 Jul 2022 14:46:14,312 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - <button_id>
12 Jul 2022 14:46:14,312 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - startField(button_id, 1)
12 Jul 2022 14:46:14,312 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - 0, VistedIndex{vistedIndexes={0}}: [button_id] r:0
12 Jul 2022 14:46:14,312 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - [111, 114, 100, 101, 114, 95, 110, 111, 116, 101, 95, 115, 101, 108, 101, 99, 116, 95, 35]
12 Jul 2022 14:46:14,312 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - addBinary(19 bytes)
12 Jul 2022 14:46:14,312 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - r: 0
12 Jul 2022 14:46:14,312 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - 0, VistedIndex{vistedIndexes={0}}: [button_id] r:0
12 Jul 2022 14:46:14,312 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - </button_id>
12 Jul 2022 14:46:14,312 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - endField(button_id, 1)
12 Jul 2022 14:46:14,312 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - 0, VistedIndex{vistedIndexes={0, 1}}: [] r:0
12 Jul 2022 14:46:14,312 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - <count>
12 Jul 2022 14:46:14,312 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - startField(count, 2)
12 Jul 2022 14:46:14,313 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - 0, VistedIndex{vistedIndexes={0, 1}}: [count] r:0
12 Jul 2022 14:46:14,313 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - 2
12 Jul 2022 14:46:14,313 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - addLong(2)
12 Jul 2022 14:46:14,313 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - r: 0
12 Jul 2022 14:46:14,313 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - 0, VistedIndex{vistedIndexes={0, 1}}: [count] r:0
12 Jul 2022 14:46:14,313 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - </count>
12 Jul 2022 14:46:14,313 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - endField(count, 2)
12 Jul 2022 14:46:14,313 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - 0, VistedIndex{vistedIndexes={0, 1, 2}}: [] r:0
12 Jul 2022 14:46:14,313 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - < MESSAGE END >
12 Jul 2022 14:46:14,313 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - 0, VistedIndex{vistedIndexes={0, 1, 2}}: [] r:0
12 Jul 2022 14:46:14,313 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - <!-- end message -->
12 Jul 2022 14:46:14,313 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - <!-- start message -->
12 Jul 2022 14:46:14,313 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - < MESSAGE START >
12 Jul 2022 14:46:14,313 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - 0, VistedIndex{vistedIndexes={}}: [] r:0
12 Jul 2022 14:46:14,313 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - <user_id_device_model>
12 Jul 2022 14:46:14,313 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - startField(user_id_device_model, 0)
12 Jul 2022 14:46:14,313 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - 0, VistedIndex{vistedIndexes={}}: [user_id_device_model] r:0
12 Jul 2022 14:46:14,313 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - [54, 48, 57, 50, 52, 53, 57, 52, 45, 56, 98, 48, 56, 45, 52, 52, 54, 98, 45, 56, 99, 57, 49, 45, 52, 53, 97, 98, 48, 97, 55, 56, 52, 99, 54, 54, 95, 105, 80, 104, 111, 110, 101]
12 Jul 2022 14:46:14,313 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - addBinary(43 bytes)
12 Jul 2022 14:46:14,313 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - r: 0
12 Jul 2022 14:46:14,313 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - 0, VistedIndex{vistedIndexes={}}: [user_id_device_model] r:0
12 Jul 2022 14:46:14,313 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - </user_id_device_model>
12 Jul 2022 14:46:14,313 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - endField(user_id_device_model, 0)
12 Jul 2022 14:46:14,313 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - 0, VistedIndex{vistedIndexes={0}}: [] r:0
12 Jul 2022 14:46:14,313 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - <button_id>
12 Jul 2022 14:46:14,313 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - startField(button_id, 1)
12 Jul 2022 14:46:14,313 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - 0, VistedIndex{vistedIndexes={0}}: [button_id] r:0
12 Jul 2022 14:46:14,313 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - [115, 101, 97, 108, 100, 101, 97, 108, 95, 101, 120, 112, 97, 110, 100]
12 Jul 2022 14:46:14,313 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - addBinary(15 bytes)
12 Jul 2022 14:46:14,313 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - r: 0
12 Jul 2022 14:46:14,313 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - 0, VistedIndex{vistedIndexes={0}}: [button_id] r:0
12 Jul 2022 14:46:14,313 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - </button_id>
12 Jul 2022 14:46:14,313 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - endField(button_id, 1)
12 Jul 2022 14:46:14,313 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - 0, VistedIndex{vistedIndexes={0, 1}}: [] r:0
12 Jul 2022 14:46:14,313 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - <count>
12 Jul 2022 14:46:14,313 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - startField(count, 2)
12 Jul 2022 14:46:14,313 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - 0, VistedIndex{vistedIndexes={0, 1}}: [count] r:0
12 Jul 2022 14:46:14,313 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - 1
12 Jul 2022 14:46:14,313 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - addLong(1)
12 Jul 2022 14:46:14,313 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - r: 0
12 Jul 2022 14:46:14,313 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - 0, VistedIndex{vistedIndexes={0, 1}}: [count] r:0
12 Jul 2022 14:46:14,313 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - </count>
12 Jul 2022 14:46:14,313 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - endField(count, 2)
12 Jul 2022 14:46:14,313 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - 0, VistedIndex{vistedIndexes={0, 1, 2}}: [] r:0
12 Jul 2022 14:46:14,313 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - < MESSAGE END >
12 Jul 2022 14:46:14,313 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - 0, VistedIndex{vistedIndexes={0, 1, 2}}: [] r:0
12 Jul 2022 14:46:14,313 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - <!-- end message -->
12 Jul 2022 14:46:14,313 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - <!-- start message -->
12 Jul 2022 14:46:14,313 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - < MESSAGE START >
12 Jul 2022 14:46:14,313 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - 0, VistedIndex{vistedIndexes={}}: [] r:0
12 Jul 2022 14:46:14,313 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - <user_id_device_model>
12 Jul 2022 14:46:14,313 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - startField(user_id_device_model, 0)
12 Jul 2022 14:46:14,313 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - 0, VistedIndex{vistedIndexes={}}: [user_id_device_model] r:0
12 Jul 2022 14:46:14,313 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - [53, 102, 50, 56, 99, 57, 50, 55, 45, 48, 54, 49, 56, 45, 52, 56, 49, 102, 45, 56, 56, 101, 101, 45, 52, 52, 51, 48, 48, 97, 54, 101, 52, 99, 52, 55, 95, 105, 80, 104, 111, 110, 101]
12 Jul 2022 14:46:14,313 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - addBinary(43 bytes)
12 Jul 2022 14:46:14,313 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - r: 0
12 Jul 2022 14:46:14,313 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - 0, VistedIndex{vistedIndexes={}}: [user_id_device_model] r:0
12 Jul 2022 14:46:14,313 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - </user_id_device_model>
12 Jul 2022 14:46:14,313 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - endField(user_id_device_model, 0)
12 Jul 2022 14:46:14,313 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - 0, VistedIndex{vistedIndexes={0}}: [] r:0
12 Jul 2022 14:46:14,313 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - <button_id>
12 Jul 2022 14:46:14,313 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - startField(button_id, 1)
12 Jul 2022 14:46:14,313 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - 0, VistedIndex{vistedIndexes={0}}: [button_id] r:0
12 Jul 2022 14:46:14,313 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - [115, 101, 97, 108, 100, 101, 97, 108, 95, 105, 110, 112, 117, 116, 95, 110, 97, 109, 101]
12 Jul 2022 14:46:14,313 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - addBinary(19 bytes)
12 Jul 2022 14:46:14,313 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - r: 0
12 Jul 2022 14:46:14,313 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - 0, VistedIndex{vistedIndexes={0}}: [button_id] r:0
12 Jul 2022 14:46:14,313 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - </button_id>
12 Jul 2022 14:46:14,313 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - endField(button_id, 1)
12 Jul 2022 14:46:14,313 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - 0, VistedIndex{vistedIndexes={0, 1}}: [] r:0
12 Jul 2022 14:46:14,313 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - <count>
12 Jul 2022 14:46:14,313 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - startField(count, 2)
12 Jul 2022 14:46:14,313 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - 0, VistedIndex{vistedIndexes={0, 1}}: [count] r:0
12 Jul 2022 14:46:14,313 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - 1
12 Jul 2022 14:46:14,313 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - addLong(1)
12 Jul 2022 14:46:14,313 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - r: 0
12 Jul 2022 14:46:14,313 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - 0, VistedIndex{vistedIndexes={0, 1}}: [count] r:0
12 Jul 2022 14:46:14,313 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - </count>
12 Jul 2022 14:46:14,313 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - endField(count, 2)
12 Jul 2022 14:46:14,313 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - 0, VistedIndex{vistedIndexes={0, 1, 2}}: [] r:0
12 Jul 2022 14:46:14,313 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - < MESSAGE END >
12 Jul 2022 14:46:14,313 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - 0, VistedIndex{vistedIndexes={0, 1, 2}}: [] r:0
12 Jul 2022 14:46:14,313 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - <!-- end message -->
12 Jul 2022 14:46:14,313 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - <!-- start message -->
12 Jul 2022 14:46:14,313 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - < MESSAGE START >
12 Jul 2022 14:46:14,313 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - 0, VistedIndex{vistedIndexes={}}: [] r:0
12 Jul 2022 14:46:14,313 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - <user_id_device_model>
12 Jul 2022 14:46:14,313 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - startField(user_id_device_model, 0)
12 Jul 2022 14:46:14,313 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - 0, VistedIndex{vistedIndexes={}}: [user_id_device_model] r:0
12 Jul 2022 14:46:14,313 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - [53, 102, 102, 49, 50, 102, 99, 51, 45, 48, 97, 50, 99, 45, 52, 55, 49, 53, 45, 56, 100, 99, 98, 45, 52, 101, 53, 52, 48, 97, 54, 101, 52, 99, 50, 54, 95, 115, 97, 109, 115, 117, 110, 103, 32, 47, 32, 83, 77, 45, 71, 54, 49, 48, 70]
12 Jul 2022 14:46:14,313 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - addBinary(55 bytes)
12 Jul 2022 14:46:14,313 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - r: 0
12 Jul 2022 14:46:14,313 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - 0, VistedIndex{vistedIndexes={}}: [user_id_device_model] r:0
12 Jul 2022 14:46:14,313 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - </user_id_device_model>
12 Jul 2022 14:46:14,313 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - endField(user_id_device_model, 0)
12 Jul 2022 14:46:14,313 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - 0, VistedIndex{vistedIndexes={0}}: [] r:0
12 Jul 2022 14:46:14,313 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - <button_id>
12 Jul 2022 14:46:14,313 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - startField(button_id, 1)
12 Jul 2022 14:46:14,313 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - 0, VistedIndex{vistedIndexes={0}}: [button_id] r:0
12 Jul 2022 14:46:14,313 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - [115, 101, 97, 108, 95, 100, 101, 97, 108, 95, 99, 117, 115, 95, 115, 101, 108, 101, 99, 116, 95, 105, 110, 112, 117, 116]
12 Jul 2022 14:46:14,313 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - addBinary(26 bytes)
12 Jul 2022 14:46:14,313 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - r: 0
12 Jul 2022 14:46:14,313 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - 0, VistedIndex{vistedIndexes={0}}: [button_id] r:0
12 Jul 2022 14:46:14,313 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - </button_id>
12 Jul 2022 14:46:14,313 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - endField(button_id, 1)
12 Jul 2022 14:46:14,313 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - 0, VistedIndex{vistedIndexes={0, 1}}: [] r:0
12 Jul 2022 14:46:14,313 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - <count>
12 Jul 2022 14:46:14,313 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - startField(count, 2)
12 Jul 2022 14:46:14,313 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - 0, VistedIndex{vistedIndexes={0, 1}}: [count] r:0
12 Jul 2022 14:46:14,313 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - 1
12 Jul 2022 14:46:14,313 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - addLong(1)
12 Jul 2022 14:46:14,313 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - r: 0
12 Jul 2022 14:46:14,313 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - 0, VistedIndex{vistedIndexes={0, 1}}: [count] r:0
12 Jul 2022 14:46:14,313 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - </count>
12 Jul 2022 14:46:14,313 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - endField(count, 2)
12 Jul 2022 14:46:14,313 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - 0, VistedIndex{vistedIndexes={0, 1, 2}}: [] r:0
12 Jul 2022 14:46:14,313 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - < MESSAGE END >
12 Jul 2022 14:46:14,313 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - 0, VistedIndex{vistedIndexes={0, 1, 2}}: [] r:0
12 Jul 2022 14:46:14,313 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - <!-- end message -->
12 Jul 2022 14:46:14,314 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - <!-- start message -->
12 Jul 2022 14:46:14,314 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - < MESSAGE START >
12 Jul 2022 14:46:14,314 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - 0, VistedIndex{vistedIndexes={}}: [] r:0
12 Jul 2022 14:46:14,314 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - <user_id_device_model>
12 Jul 2022 14:46:14,314 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - startField(user_id_device_model, 0)
12 Jul 2022 14:46:14,314 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - 0, VistedIndex{vistedIndexes={}}: [user_id_device_model] r:0
12 Jul 2022 14:46:14,314 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - [53, 101, 101, 52, 50, 54, 53, 99, 45, 99, 51, 54, 56, 45, 52, 49, 54, 102, 45, 56, 52, 52, 50, 45, 52, 54, 99, 101, 48, 97, 54, 101, 52, 99, 50, 52, 95, 105, 80, 104, 111, 110, 101]
12 Jul 2022 14:46:14,314 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - addBinary(43 bytes)
12 Jul 2022 14:46:14,314 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - r: 0
12 Jul 2022 14:46:14,314 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - 0, VistedIndex{vistedIndexes={}}: [user_id_device_model] r:0
12 Jul 2022 14:46:14,314 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - </user_id_device_model>
12 Jul 2022 14:46:14,314 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - endField(user_id_device_model, 0)
12 Jul 2022 14:46:14,314 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - 0, VistedIndex{vistedIndexes={0}}: [] r:0
12 Jul 2022 14:46:14,314 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - <button_id>
12 Jul 2022 14:46:14,314 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - startField(button_id, 1)
12 Jul 2022 14:46:14,314 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - 0, VistedIndex{vistedIndexes={0}}: [button_id] r:0
12 Jul 2022 14:46:14,314 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - [111, 114, 100, 101, 114, 115]
12 Jul 2022 14:46:14,314 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - addBinary(6 bytes)
12 Jul 2022 14:46:14,314 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - r: 0
12 Jul 2022 14:46:14,314 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - 0, VistedIndex{vistedIndexes={0}}: [button_id] r:0
12 Jul 2022 14:46:14,314 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - </button_id>
12 Jul 2022 14:46:14,314 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - endField(button_id, 1)
12 Jul 2022 14:46:14,314 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - 0, VistedIndex{vistedIndexes={0, 1}}: [] r:0
12 Jul 2022 14:46:14,314 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - <count>
12 Jul 2022 14:46:14,314 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - startField(count, 2)
12 Jul 2022 14:46:14,314 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - 0, VistedIndex{vistedIndexes={0, 1}}: [count] r:0
12 Jul 2022 14:46:14,314 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - 1
12 Jul 2022 14:46:14,314 Executor task launch worker for task 0.0 in stage 11.0 (TID 1006) - addLong(1)
